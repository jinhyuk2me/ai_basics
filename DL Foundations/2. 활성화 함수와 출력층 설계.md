## TL;DR
- 활성화 함수 선택이 표현력·학습 안정성에 미치는 영향을 정리합니다.
- 출력층과 손실 함수 조합으로 문제 유형별 모델 구성을 안내합니다.

## 비교 포인트
- 활성화 함수별 수학적 형태와 미분 특성
- 포화 문제, 기울기 소실과 폭발을 완화하는 전략
- 출력층 설계 시 확률 해석 여부(softmax, sigmoid)와 회귀용 선형 출력 대비

## 적용 시나리오
- 분류, 다중 라벨, 회귀, 순위 학습 등에서의 출력층·손실 매칭
- 딥 네트워크 심층부 vs 후반부에서의 활성화 함수 조합 패턴
- 배치 정규화·드롭아웃과의 상호작용 고려 사항

## 실험 체크리스트
- 동일 데이터셋에서 활성화 함수 교체 실험 계획
- 출력층 로짓 스케일 안정화를 위한 초기화·스케일링 전략
- 학습 곡선·로그 기록에서 확인할 지표 정리

## 관련 노트
- [[DL Foundations/1. 신경망 기본 구조]]
- [[ML Foundations/4. 정규화와 일반화]]
- [[DL Foundations/3. 역전파와 최적화 전략]]
