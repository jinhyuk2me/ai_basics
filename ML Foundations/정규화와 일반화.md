## TL;DR
- 정규화(regularization)는 모델의 자유도를 제한하거나 데이터에 노이즈를 주입해 과적합을 줄이고 일반화(generalization)를 향상시키는 전략이다.
- Bias-Variance 트레이드오프 관점에서 모델 복잡도를 관리하고, L1/L2, Dropout, Data Augmentation, Early Stopping, Ensemble 등 다양한 기법을 상황에 맞게 조합한다.
- 일반화 성능을 검증하려면 검증 세트와 교차 검증, 학습 곡선 분석이 필수적이다.

## 핵심 개념
- **Bias-Variance Trade-off**
  - Bias: 모델이 단순해 데이터 패턴을 제대로 잡지 못할 때 발생하는 오류.
  - Variance: 모델이 복잡해 학습 데이터의 잡음까지 학습할 때 발생하는 오류.
  - 목표는 두 오류를 균형 있게 줄이는 것. 정규화는 주로 variance를 줄여 generalization을 개선.
- **모델 용량과 VC Dimension**
  - 모델의 복잡도가 높을수록 VC dimension이 증가해 훈련 데이터는 맞추지만 일반화 성능이 낮을 수 있다.
- **패널티 기반 정규화**
  - L2(가중치 감소): `λ ||w||_2^2`, 큰 가중치를 억제해 smooth한 함수 유도.
  - L1(라소): `λ ||w||_1`, 희소성 유도, feature selection과 연관.
  - Elastic Net: L1+L2 혼합.
- **Dropout & 노이즈 주입**
  - Dropout: 학습 과정에서 뉴런을 확률적으로 비활성화 → ensemble 효과.
  - Gaussian Noise: 입력 또는 가중치에 노이즈 추가, 데이터 증강과 유사한 역할.
- **데이터 증강(Data Augmentation)**
  - 이미지: 회전, 반전, 색상 변환, CutMix, Mixup.
  - 텍스트: synonym replacement, back-translation.
  - 오디오: time stretch, pitch shift.
- **Early Stopping**
  - 검증 성능이 악화되기 시작하면 조기 종료 → variance 증가를 막는 간단하고 강력한 방법.
- **Ensemble**
  - 여러 모델의 예측을 평균/가중 평균 → 분산 감소, 일반화 향상.
  - Bagging, Boosting, Snapshot Ensemble, SWA.
- **Label Smoothing & Knowledge Distillation**
  - 라벨을 one-hot 대신 soft target으로 바꾸어 confidence를 낮추고 일반화 향상.
  - 큰 모델에서 작은 모델로 지식을 전이.

## 실습 아이디어
- 동일 모델에 L1/L2 패널티를 각각 적용, 가중치 분포와 정확도의 차이를 비교.
- Dropout 비율 0.1, 0.3, 0.5로 변경하며 검증 손실 곡선을 그려 최적 비율 선택.
- 이미지 데이터에서 기본 Augmentation vs Mixup vs CutMix를 비교하고 overfitting 감소 여부 관찰.
- Early stopping 유무에 따른 학습/검증 손실 곡선을 비교, patience 값 조정 실험.
- Snapshot ensemble 또는 SWA를 적용해 단일 모델 대비 일반화 향상을 확인.

## 일반화 성능 측정 팁
- 학습 곡선(Training vs Validation loss)을 그려 과소적합/과적합 여부 판단.
- K-fold 교차 검증으로 평가의 신뢰도를 높이고 하이퍼파라미터 선택.
- Calibration (Brier score, ECE)으로 예측 확률의 신뢰도 확인.

## 추천 참고 자료
- *Deep Learning* (Goodfellow), Chapter 7
- Andrew Ng, *CS229 Lecture on Regularization*
- Baldi & Sadowski, *Understanding Dropout* (arXiv:1312.6197)

## 다음 학습
- [[Evaluation/Validation and Early Stopping]]
- [[Training/Regularization Techniques]]
- [[Projects/Image Classification Pipeline]]
