## TL;DR
- 손실 함수(loss)는 학습 중 최적화하려는 목표를 수치화하고, 평가 지표(metric)는 모델이 실제로 얼마나 잘 동작하는지 측정한다.
- 분류, 회귀, 랭킹 등 각 문제 유형에 맞는 손실·지표 조합을 이해하고, 클래스 불균형이나 확률 보정(calibration) 이슈를 해결할 전략을 마련해야 한다.
- 손실과 지표가 불일치하면 학습 방향이 어긋날 수 있으므로, 지표를 surrogate loss로 근사하거나 커스텀 손실을 설계하기도 한다.

## 손실 함수 분류
- **경험적 위험 최소화(ERM)**
  - 전체 데이터에 대한 평균 손실 `L(θ) = (1/N) Σ ℓ(f_θ(x_i), y_i)`를 최소화.
  - 학습률, 정규화, 옵티마이저는 이 손실을 기준으로 동작한다.
- **분류 손실**
  - Cross Entropy: 확률 분포 간 차이를 측정, softmax와 함께 사용.
  - Binary Cross Entropy / BCEWithLogits: 시그모이드와 함께 사용, 로그 확률 최적화.
  - Focal Loss: 희귀 클래스에서 손실 가중치를 높여 클래스 불균형 완화.
  - Hinge Loss / Margin Loss: 최대 마진 분류(SVM)의 surrogate loss.
- **회귀 손실**
  - L2(MSE): 큰 오차에 민감, 미분 가능.
  - L1(MAE): outlier에 강인, 미분 불연속 → subgradient 사용.
  - Huber Loss: L1과 L2 사이의 타협, δ 파라미터로 전환 지점 제어.
  - Quantile Loss: 지표 예측(예: 90% 분위수).
- **랭킹/추천 손실**
  - Pairwise hinge, BPR(Bayesian Personalized Ranking).
  - Listwise(Softmax cross entropy over permutations) → LambdaRank, ListNet.
- **기타 손실**
  - GAN: min-max objective (`min_G max_D E[log D(x)] + E[log(1 - D(G(z)))]`).
  - Contrastive Loss / InfoNCE: representation learning.
  - KL divergence, JS divergence: 확률 분포 간 거리.

## 평가 지표 개요
- 분류 지표: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC.
- 회귀 지표: RMSE, MAE, R², MAPE.
- 불균형 데이터: Balanced Accuracy, MCC, F-beta.
- 랭킹: MAP, NDCG, Hit@K.
- Calibration: Brier Score, Expected Calibration Error(ECE).

## 손실과 지표의 불일치 문제
- Accuracy를 높이고 싶지만 Cross Entropy가 surrogate loss로 사용된다 → 일반적으로 잘 대응하지만 클래스 불균형 시 precision/recall을 직접 고려해야 함.
- F1-score는 미분 불가능 → differentiable surrogate(Focal loss, differentiable F-measure) 사용.
- ROC-AUC를 직접 최적화하기 어렵기 때문에, pairwise loss로 대체하거나 differentiable approximation을 사용.

## PyTorch에서 손실/지표 사용 예
```python
import torch
import torch.nn.functional as F

logits = torch.randn(8, 5)
targets = torch.randint(0, 5, (8,))

loss = F.cross_entropy(logits, targets)

pred = logits.argmax(dim=1)
accuracy = (pred == targets).float().mean()
print("loss=", loss.item(), "accuracy=", accuracy.item())
```
- 손실은 gradient를 통해 학습에 사용되며, 지표는 gradient가 끊기더라도 SKlearn 또는 PyTorch Lightning metric 등으로 계산해 기록한다.

## 실습 아이디어
- Imbalanced 데이터셋(예: class 1 비율 5%)에서 Cross Entropy vs Focal Loss 성능 비교.
- Regression에서 MSE vs MAE vs Huber를 사용해 outlier 영향을 비교.
- ROC curve, PR curve를 직접 계산하고, threshold를 바꿔 F1-score와 정확도의 trade-off를 시각화.
- Calibration curve(reliability diagram)를 그려 softmax 확률이 실제 비율과 얼마나 일치하는지 확인.

## 추천 참고 자료
- *Deep Learning* (Goodfellow), Chapter 5.5–5.7
- Stanford CS229 Lecture 2: Loss functions and Classification
- Niculescu-Mizil & Caruana, *Predicting Good Probabilities with Supervised Learning*

## 다음 학습
- [[ML Foundations/머신러닝 최적화]]
- [[Evaluation/Metrics]]
- [[Training/Loss Functions]]
