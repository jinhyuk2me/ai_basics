## TL;DR
- **그래프(Graph)**는 노드(vertices)와 엣지(edges)로 구성된 수학적 구조로, 관계형 데이터를 자연스럽게 표현한다.
- 인접 행렬, 인접 리스트, 엣지 리스트 등 다양한 표현 방식이 있으며, 각각 메모리와 연산 효율성에서 장단점이 있다.
- 그래프의 기본 성질(차수, 경로, 연결성)을 이해하면 GNN, 추천 시스템, 소셜 네트워크 분석의 기초가 된다.

---

## 1. 핵심 개념

### 1.1 그래프의 정의

**수학적 정의**:
그래프 $G = (V, E)$는 다음으로 구성:
- $V$: 노드(vertex, node) 집합
- $E \subseteq V \times V$: 엣지(edge) 집합

**예시**:
$$
V = \{1, 2, 3, 4\}, \quad E = \{(1,2), (1,3), (2,3), (3,4)\}
$$

```
1 --- 2
 \   /
  \ /
   3 --- 4
```

### 1.2 그래프의 종류

**무방향 그래프 (Undirected Graph)**:
- 엣지에 방향 없음: $(u, v) = (v, u)$
- 예: 친구 관계, 도로 네트워크

**방향 그래프 (Directed Graph, Digraph)**:
- 엣지에 방향 있음: $(u, v) \ne (v, u)$
- 예: 웹 페이지 링크, 인용 그래프

**가중 그래프 (Weighted Graph)**:
- 각 엣지에 가중치 $w: E \to \mathbb{R}$
- 예: 도로의 거리, 네트워크 대역폭

**기타**:
- **다중 그래프 (Multigraph)**: 두 노드 간 여러 엣지 허용
- **자기 루프 (Self-loop)**: $(v, v)$ 형태 엣지
- **이분 그래프 (Bipartite)**: $V = V_1 \cup V_2$, 엣지는 $V_1$과 $V_2$ 사이만

---

## 2. 수학적 전개

### 2.1 차수 (Degree)

**무방향 그래프**:
$$
\deg(v) = |\{u \in V : (v, u) \in E\}|
$$
(노드 $v$에 인접한 엣지 개수)

**Handshaking Lemma**:
$$
\sum_{v \in V} \deg(v) = 2|E|
$$

**증명**:
각 엣지는 두 노드의 차수에 기여 → 총합은 $2|E|$ ∎

**방향 그래프**:
- **In-degree**: $\deg^-(v) = |\{u : (u, v) \in E\}|$
- **Out-degree**: $\deg^+(v) = |\{u : (v, u) \in E\}|$
- $\sum_v \deg^-(v) = \sum_v \deg^+(v) = |E|$

### 2.2 경로와 순환

**경로 (Path)**:
노드 열 $v_0, v_1, \ldots, v_k$이며 $(v_i, v_{i+1}) \in E$
- **Simple path**: 노드가 반복 안 됨
- **길이**: 엣지 개수 $k$

**순환 (Cycle)**:
$v_0 = v_k$인 경로
- **Acyclic graph**: 순환이 없는 그래프

**트리 (Tree)**:
- 연결되고(connected) acyclic한 무방향 그래프
- $n$개 노드, $n-1$개 엣지

### 2.3 연결성 (Connectivity)

**연결 그래프 (Connected Graph)**:
임의의 두 노드 $u, v$에 대해 경로 존재

**연결 요소 (Connected Component)**:
- 최대 연결 부분 그래프
- 그래프를 분리된 부분으로 분해

**강연결 (Strongly Connected, for directed)**:
임의의 $u, v$에 대해 $u \to v$ 경로와 $v \to u$ 경로 모두 존재

**거리 (Distance)**:
$$
d(u, v) = \min \{\text{length of path from } u \text{ to } v\}
$$

**직경 (Diameter)**:
$$
\text{diam}(G) = \max_{u, v \in V} d(u, v)
$$

---

## 3. 그래프 표현 방식

### 3.1 인접 행렬 (Adjacency Matrix)

**정의**:
$n \times n$ 행렬 $A$:
$$
A_{ij} = \begin{cases}
1 & \text{if } (i, j) \in E \\
0 & \text{otherwise}
\end{cases}
$$

가중 그래프에서는 $A_{ij} = w(i, j)$ (가중치)

**예시**:
```
Graph:     1 → 2
           ↓ ↗
           3

Adjacency Matrix:
    1  2  3
1 [ 0  1  1 ]
2 [ 0  0  0 ]
3 [ 0  1  0 ]
```

**장점**:
- $O(1)$에 엣지 존재 확인: `A[i][j]`
- 행렬 연산으로 경로 계산: $A^k_{ij}$ = $i$에서 $j$로 길이 $k$ 경로 수

**단점**:
- $O(n^2)$ 메모리 (희소 그래프에서 낭비)
- 모든 엣지 순회: $O(n^2)$

### 3.2 인접 리스트 (Adjacency List)

**정의**:
각 노드 $v$에 대해 인접 노드 리스트 저장

**예시**:
```
1: [2, 3]
2: []
3: [2]
```

**구현**:
```python
# Dictionary of lists
adj_list = {
    1: [2, 3],
    2: [],
    3: [2]
}

# 또는 리스트의 리스트
adj_list = [
    [2, 3],  # 노드 0
    [],      # 노드 1
    [1]      # 노드 2
]
```

**장점**:
- $O(n + m)$ 메모리 ($m = |E|$)
- 이웃 순회: $O(\deg(v))$
- 희소 그래프에 효율적

**단점**:
- 엣지 존재 확인: $O(\deg(v))$
- 무방향 그래프는 각 엣지를 2번 저장

### 3.3 엣지 리스트 (Edge List)

**정의**:
엣지들의 리스트: $[(u_1, v_1), (u_2, v_2), \ldots]$

가중 그래프: $[(u_1, v_1, w_1), (u_2, v_2, w_2), \ldots]$

**예시**:
```python
edges = [(1, 2), (1, 3), (3, 2)]
weighted_edges = [(1, 2, 0.5), (1, 3, 1.2), (3, 2, 0.8)]
```

**장점**:
- 간단한 저장 형식 (CSV, JSON)
- 엣지 기반 연산에 효율적
- $O(m)$ 메모리

**단점**:
- 특정 노드의 이웃 찾기: $O(m)$
- 엣지 존재 확인: $O(m)$ (정렬 후 $O(\log m)$)

### 3.4 표현 방식 비교

| 연산 | 인접 행렬 | 인접 리스트 | 엣지 리스트 |
|------|----------|-----------|------------|
| **메모리** | $O(n^2)$ | $O(n + m)$ | $O(m)$ |
| **엣지 확인** | $O(1)$ | $O(\deg(v))$ | $O(m)$ |
| **이웃 찾기** | $O(n)$ | $O(\deg(v))$ | $O(m)$ |
| **모든 엣지** | $O(n^2)$ | $O(n + m)$ | $O(m)$ |
| **엣지 추가** | $O(1)$ | $O(1)$ | $O(1)$ |

**선택 기준**:
- **밀집 그래프** ($m \approx n^2$): 인접 행렬
- **희소 그래프** ($m \ll n^2$): 인접 리스트
- **데이터 로딩/저장**: 엣지 리스트

---

## 4. 특수 그래프

### 4.1 완전 그래프 (Complete Graph) $K_n$

모든 노드 쌍이 연결:
$$
|E| = \binom{n}{2} = \frac{n(n-1)}{2}
$$

### 4.2 이분 그래프 (Bipartite Graph)

$V = L \cup R$, 엣지는 $L$과 $R$ 사이만

**판별 조건**:
그래프가 이분 $\Leftrightarrow$ 홀수 길이 순환 없음

**Hall's Marriage Theorem**:
완벽한 매칭 존재 조건

### 4.3 평면 그래프 (Planar Graph)

교차 없이 평면에 그릴 수 있는 그래프

**Euler's Formula**:
$$
|V| - |E| + |F| = 2
$$
($F$: face 개수)

**Kuratowski's Theorem**:
$K_5$나 $K_{3,3}$의 subdivision을 부분 그래프로 포함하지 않으면 planar

---

## 5. 그래프 특성 지표

### 5.1 밀도 (Density)

$$
\text{density} = \frac{2|E|}{|V|(|V|-1)}
$$
(무방향 그래프, 범위 $[0, 1]$)

- **Dense graph**: density ≈ 1
- **Sparse graph**: density ≈ 0

### 5.2 클러스터링 계수 (Clustering Coefficient)

**노드 $v$의 클러스터링 계수**:
$$
C(v) = \frac{\text{# triangles connected to } v}{\binom{\deg(v)}{2}}
$$
(이웃들 간 연결 비율)

**전체 그래프**:
$$
C = \frac{1}{|V|} \sum_{v \in V} C(v)
$$

**의미**:
- 높으면 친구의 친구도 친구 (소셜 네트워크)
- Small-world 특성의 지표

### 5.3 평균 경로 길이

$$
L = \frac{1}{|V|(|V|-1)} \sum_{u \ne v} d(u, v)
$$

**Small-World Property**:
$L \sim \log |V|$ (노드 수에 logarithmic)

### 5.4 차수 분포 (Degree Distribution)

$P(k)$: 차수가 $k$인 노드 비율

**Scale-Free Networks**:
$$
P(k) \sim k^{-\gamma} \quad \text{(power law)}
$$
- 소수의 hub 노드(높은 차수)
- 예: 인터넷, 소셜 네트워크, 인용 그래프

---

## 6. PyTorch Geometric 구현

### 6.1 그래프 생성

```python
import torch
from torch_geometric.data import Data

# 엣지 리스트 (COO format)
edge_index = torch.tensor([
    [0, 1, 1, 2],  # source nodes
    [1, 0, 2, 1]   # target nodes
], dtype=torch.long)

# 노드 특징 (4개 노드, 각 3차원)
x = torch.tensor([
    [1.0, 0.0, 0.5],
    [0.5, 1.0, 0.2],
    [0.2, 0.3, 1.0],
    [0.8, 0.1, 0.4]
], dtype=torch.float)

# 그래프 객체
data = Data(x=x, edge_index=edge_index)

print(f"Nodes: {data.num_nodes}")
print(f"Edges: {data.num_edges}")
print(f"Directed: {data.is_directed()}")
```

### 6.2 인접 행렬 변환

```python
from torch_geometric.utils import to_dense_adj, to_scipy_sparse_matrix

# 밀집 인접 행렬
adj_dense = to_dense_adj(edge_index)[0]
print("Adjacency Matrix:\n", adj_dense)

# 희소 행렬 (scipy)
adj_sparse = to_scipy_sparse_matrix(edge_index)
print("Sparse shape:", adj_sparse.shape)
print("Non-zero entries:", adj_sparse.nnz)
```

### 6.3 NetworkX 연동

```python
import networkx as nx
from torch_geometric.utils import from_networkx, to_networkx

# NetworkX 그래프 생성
G_nx = nx.karate_club_graph()

# PyG로 변환
data = from_networkx(G_nx)
print("Converted to PyG:", data)

# PyG에서 NetworkX로
G_nx_back = to_networkx(data, to_undirected=True)
print("NetworkX graph:", G_nx_back)
```

### 6.4 그래프 특성 계산

```python
import networkx as nx

G = nx.karate_club_graph()

# 차수
degrees = dict(G.degree())
print("Max degree:", max(degrees.values()))

# 클러스터링 계수
clustering = nx.clustering(G)
avg_clustering = sum(clustering.values()) / len(clustering)
print(f"Average clustering: {avg_clustering:.3f}")

# 평균 경로 길이
avg_path_length = nx.average_shortest_path_length(G)
print(f"Average path length: {avg_path_length:.3f}")

# 차수 분포
degree_sequence = sorted([d for n, d in G.degree()], reverse=True)
print("Degree distribution:", degree_sequence[:10])
```

---

## 7. 실전 가이드

### 7.1 그래프 표현 선택

| 상황 | 추천 표현 |
|------|----------|
| **GNN 학습** | 엣지 리스트 (PyG의 `edge_index`) |
| **최단 경로 반복** | 인접 리스트 |
| **행렬 연산 (스펙트럴)** | 인접 행렬 (희소 행렬) |
| **데이터 저장** | 엣지 리스트 (CSV) |
| **밀집 그래프** | 인접 행렬 |

### 7.2 메모리 효율

**희소 그래프 최적화**:
```python
import scipy.sparse as sp

# COO → CSR (빠른 행 접근)
adj_csr = adj_sparse.tocsr()

# 특정 노드의 이웃
neighbors = adj_csr[node_id].nonzero()[1]

# 메모리 사용량
print(f"Dense: {adj_dense.nbytes / 1e6} MB")
print(f"Sparse: {(adj_sparse.data.nbytes + adj_sparse.indices.nbytes) / 1e6} MB")
```

### 7.3 대규모 그래프 처리

**Batching**:
```python
from torch_geometric.loader import DataLoader

# 여러 그래프를 배치로
loader = DataLoader(graph_list, batch_size=32, shuffle=True)

for batch in loader:
    # batch.x: [total_nodes, feature_dim]
    # batch.batch: 각 노드가 속한 그래프 ID
    out = model(batch.x, batch.edge_index, batch.batch)
```

**Sampling** (대규모 단일 그래프):
```python
from torch_geometric.loader import NeighborLoader

# k-hop neighbor sampling
loader = NeighborLoader(
    data,
    num_neighbors=[10, 5],  # 1-hop: 10, 2-hop: 5
    batch_size=128,
    input_nodes=train_mask
)
```

---

## 8. 실습 과제

1. **표현 방식 비교**
   - 1000개 노드, 5000개 엣지 랜덤 그래프 생성
   - 인접 행렬, 인접 리스트로 각각 구현
   - 메모리 사용량과 엣지 확인 시간 측정

2. **그래프 특성 분석**
   - Zachary's Karate Club 그래프 로드
   - 차수 분포, 클러스터링 계수, 경로 길이 계산
   - 결과 시각화 및 해석

3. **이분 그래프 판별**
   - BFS로 2-coloring 시도
   - 홀수 길이 순환 발견 시 False 반환
   - NetworkX의 `is_bipartite()`와 비교

4. **Scale-Free 그래프 생성**
   - Barabási-Albert 모델로 그래프 생성 ($n=1000, m=3$)
   - 차수 분포를 log-log plot
   - Power-law 지수 $\gamma$ 추정

5. **PyG 데이터셋 탐색**
   - `torch_geometric.datasets.Planetoid`에서 Cora 로드
   - 노드/엣지 수, 특징 차원, 클래스 수 확인
   - 그래프 시각화 (NetworkX + matplotlib)

---

## 9. 참고 자료

### 교과서
- Reinhard Diestel, *Graph Theory*, 5th ed.
- Douglas West, *Introduction to Graph Theory*
- Fan R. K. Chung, *Spectral Graph Theory*

### 온라인 강의
- Stanford CS224W: Machine Learning with Graphs
- MIT 6.042J: Mathematics for Computer Science (Graph Theory section)

### 라이브러리
- NetworkX: https://networkx.org/
- PyTorch Geometric: https://pytorch-geometric.readthedocs.io/
- DGL (Deep Graph Library): https://www.dgl.ai/

---

## 10. 다음 학습

그래프 기초를 마쳤다면:

1. **그래프 알고리즘**
   - [[그래프 알고리즘|그래프 알고리즘 상세 노트]]
   - BFS, DFS, Dijkstra, MST

2. **스펙트럴 이론과 GNN**
   - [[스펙트럴 그래프 이론과 GNN|스펙트럴 그래프와 GNN]]
   - Laplacian, GCN, message passing

3. **선형대수 연결**
   - [[Math/Linear Algebra/고유값과 고유벡터|고유값]]
   - 인접 행렬의 고유값과 그래프 특성

4. **상위 개념**
   - [[그래프 이론|그래프 이론 허브]]
