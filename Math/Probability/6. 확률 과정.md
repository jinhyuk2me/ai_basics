## TL;DR
- 확률 과정은 시간(또는 지표)에 따라 변하는 확률 변수들의 집합으로, 마르코프 체인과 MDP가 강화학습·시계열 모델의 이론적 토대를 이룬다.
- 전이행렬, 정상분포, 포아송/브라운 운동과 같은 고전 과정은 MCMC, Diffusion, Hidden Markov Model, Stochastic Control을 이해하는 핵심 개념이다.
- PyTorch/NumPy 시뮬레이션으로 전이 확률, 수렴 속도, MCMC mixing을 실험하면 RL/생성 모델의 안정성을 정량화할 수 있다.

## 언제 쓰나
- 강화학습에서 환경 동역학을 마르코프 결정 과정(MDP)으로 모델링하고, 정책 평가/개선을 분석할 때
- Metropolis-Hastings, Gibbs Sampling, Diffusion Models처럼 확률 과정을 이용해 샘플을 생성할 때
- HMM, Kalman Filter, 시계열 예측 모델에서 상태 전이를 정의하거나 EM 알고리즘을 유도할 때
- 베이지안 최적화/Active Learning에서 상태-행동-보상 삼중을 수리적으로 다루어 탐색 전략을 설계할 때

## 주요 API
| 개념 | 정의/요약 | 실습 포인트 |
| --- | --- | --- |
| 이산 마르코프 체인 | $P(X_{t+1}=j \mid X_t=i) = P_{ij}$, 과거와 무관 | 전이행렬 거듭제곱, 정상분포 계산 |
| 연속 마르코프 체인 | $Q$-행렬(발생률)로 정의, Poisson clock | 작은 $dt$ 시뮬레이션, 유한 상태 근사 |
| 정상분포(Stationary) | $\pi = \pi P$, 체인이 수렴하는 분포 | 선형방정식 풀이, 지배 고유벡터 |
| 마르코프 결정 과정 | $(\mathcal{S}, \mathcal{A}, P, R, \gamma)$ | Bellman 방정식, 정책 반복 |
| 포아송 과정 | 독립 증가, $N(t) \sim \text{Poisson}(\lambda t)$ | 도착 간격 지수분포 시뮬레이션 |
| 브라운 운동 | 연속 시간·연속 상태, $B(t)$ 정규분포 증가 | Euler-Maruyama 근사 |
| MCMC | 사후 분포를 target으로 하는 체인 설계 | Metropolis-Hastings, Gibbs |
| Diffusion(Stochastic) | 역 SDE/정방향 노이즈 주입 | 디노이징, score matching |

## 실습 예제
### 1. 전이행렬로 마르코프 체인 시뮬레이션 및 정상분포 확인
```python
import random
import math

P = [
    [0.6, 0.3, 0.1],
    [0.2, 0.5, 0.3],
    [0.1, 0.3, 0.6],
]
state = 0
counts = [0, 0, 0]
T = 10000
for t in range(T):
    counts[state] += 1
    r = random.random()
    cumulative = 0.0
    for next_state, prob in enumerate(P[state]):
        cumulative += prob
        if r <= cumulative:
            state = next_state
            break
freq = [c / T for c in counts]
print('empirical freq:', [round(f, 3) for f in freq])
```
- 위 체인의 전이행렬에 대해 선형 시스템 $\pi P = \pi$를 풀면 $\pi \approx (0.333, 0.333, 0.334)$.
- 시뮬레이션 결과도 $[0.335, 0.333, 0.332]$ 수준으로 수렴하여 정상분포를 관찰할 수 있다.

### 2. 포아송 과정과 지수 간격 검증
```python
import random
import math

lam = 2.0
T = 5.0
arrivals = []
t = 0.0
while t < T:
    gap = -math.log(1 - random.random()) / lam  # Exponential(λ)
    t += gap
    if t < T:
        arrivals.append(t)
print('num events', len(arrivals))
print('avg inter-arrival', sum(arrivals[i] - arrivals[i-1] if i>0 else arrivals[0] for i in range(len(arrivals))) / len(arrivals))
```
- 포아송 과정의 도착 간격은 지수분포이므로 `-log(1-U)/λ`로 샘플링한다.
- 여러 번 반복해 평균 간격이 $1/\lambda$에 근접하는지 확인하고, $N(T)$의 분포가 Poisson$(\lambda T)$와 일치하는지 카이제곱 검정을 수행할 수 있다.

### 3. 간단한 Metropolis-Hastings로 타겟 분포 샘플링
```python
import random
import math

# Target: mixture of two Gaussians
weights = [0.4, 0.6]
means = [-2.0, 2.0]
stds = [0.5, 0.5]

def log_target(x):
    return math.log(sum(w / (math.sqrt(2*math.pi)*s) * math.exp(-0.5*((x-m)/s)**2) for w, m, s in zip(weights, means, stds)))

samples = []
current = 0.0
current_lp = log_target(current)
proposal_std = 1.0
for step in range(20000):
    cand = current + random.gauss(0, proposal_std)
    cand_lp = log_target(cand)
    if math.log(random.random()) < cand_lp - current_lp:
        current, current_lp = cand, cand_lp
    if step > 1000 and step % 5 == 0:
        samples.append(current)
print('sample mean ~', sum(samples)/len(samples))
```
- 수집한 샘플 히스토그램을 그리면 두 개의 모드가 잘 나타나며, 제안 분산을 조절해 mixing 속도를 관찰할 수 있다.
- 이 구조는 VAE/Diffusion의 noise schedule을 설계하거나, 베이지안 추론에서 사후 분포 근사를 검증하는 데 활용된다.

### 4. 간단한 MDP 정책 평가 (벨만 연산자 고정점)
```python
P_pi = [
    [0.7, 0.3],
    [0.4, 0.6],
]
R = [1.0, 2.0]
gamma = 0.9
V = [0.0, 0.0]
for _ in range(100):
    V = [
        R[0] + gamma * (P_pi[0][0]*V[0] + P_pi[0][1]*V[1]),
        R[1] + gamma * (P_pi[1][0]*V[0] + P_pi[1][1]*V[1]),
    ]
print('value function', V)
```
- 벨만 연산자 $T^\\pi$ 반복으로 고정점 $V^\\pi = (I - \gamma P^\\pi)^{-1} r$에 수렴한다.
- 강화학습 구현 시, 실제 샘플링으로 추정한 $V$와 선형 시스템 해를 비교해 편향 여부를 측정할 수 있다.

## 실수 주의
- 비가역/비주기 체인은 정상분포가 존재하지 않을 수 있으니, 불변 측(irreducibility)과 비주기성(aperiodicity)을 먼저 확인한다.
- MCMC 제안분포가 너무 좁으면 체인이 mixing하지 못하고, 너무 넓으면 accept 비율이 급격히 떨어지므로 0.2~0.5 범위를 목표로 조정한다.
- 포아송 과정 시뮬레이션에서 `-log(U)/λ` 대신 `U/λ`를 사용하면 지수분포가 아닌 균일분포가 되어 전체 모델이 붕괴한다.
- MDP에서 할인율 $\gamma \ge 1$ 또는 비정상 보상 함수를 사용하면 벨만 연산자가 수렴하지 않는다.
- 연속 과정(브라운 운동) 시뮬레이션 시 Euler-Maruyama의 시간 스텝이 너무 크면 분산이 과대/과소 추정되어 Diffusion 모델 학습이 불안정해진다.

## 관련 노트
- [[Math/Probability/2. 확률 기초]]
- [[Math/Probability/3. 통계적 추론]]
- [[Foundations/7. 역전파와 최적화 전략]]
- [[Foundations/3. 최적화]]
- [[Operators/3. 합성곱 연산자]]
- [[Math/Math_확장_계획]]
