## TL;DR
- 확률 이론은 불확실성을 정량화하는 수학적 체계로, 딥러닝의 손실 함수, 베이지안 추론, 생성 모델의 토대다.
- 확률 공간의 공리부터 시작하여 확률 변수, 분포, 기댓값, 조건부 확률, 베이즈 정리까지 체계적으로 다룬다.
- 이산/연속 분포의 주요 특성과 다변량 정규분포는 딥러닝 전반에서 반복적으로 등장한다.

---

## 1. 확률 공간

### 1.1 공리적 정의 (Kolmogorov Axioms)

**정의**: 확률 공간은 삼중쌍 $(\Omega, \mathcal{F}, P)$:
- $\Omega$: 표본 공간 (sample space) - 모든 가능한 결과
- $\mathcal{F}$: 사건 공간 (event space) - $\Omega$의 부분집합들의 σ-algebra
- $P$: 확률 측도 (probability measure)

**공리**:
1. **비음수성**: $P(A) \geq 0$ for all $A \in \mathcal{F}$
2. **정규화**: $P(\Omega) = 1$
3. **가법성**: 서로 배타적인 사건 $A_1, A_2, \ldots$에 대해
   $$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$$

### 1.2 기본 성질

**정리**:
- $P(\emptyset) = 0$
- $P(A^c) = 1 - P(A)$ (여집합)
- $A \subseteq B \Rightarrow P(A) \leq P(B)$ (단조성)
- $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ (포함-배제 원리)

**증명** (포함-배제):
$$
P(A \cup B) = P(A) + P(B \setminus (A \cap B))
$$
$$
= P(A) + P(B) - P(A \cap B) \quad \text{∎}
$$

### 1.3 예제

**예제 1 (주사위)**:
- $\Omega = \{1, 2, 3, 4, 5, 6\}$
- $\mathcal{F} = 2^{\Omega}$ (모든 부분집합)
- $P(\{k\}) = 1/6$ for $k = 1, \ldots, 6$

**예제 2 (연속)**:
- $\Omega = [0, 1]$
- $P([a, b]) = b - a$ for $0 \leq a \leq b \leq 1$

---

## 2. 확률 변수

### 2.1 정의

**정의**: 확률 변수 $X$는 가측 함수 $X: \Omega \rightarrow \mathbb{R}$
$$
X^{-1}(B) = \{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{F}
$$

**직관**: 표본 공간을 실수로 매핑. "실험 결과를 숫자로 바꾼다"

### 2.2 분포 함수

**누적분포함수 (CDF)**:
$$
F_X(x) = P(X \leq x)
$$

**성질**:
- 비감소: $x \leq y \Rightarrow F_X(x) \leq F_X(y)$
- 우연속: $\lim_{h \to 0^+} F_X(x + h) = F_X(x)$
- $\lim_{x \to -\infty} F_X(x) = 0$, $\lim_{x \to \infty} F_X(x) = 1$

### 2.3 이산 vs 연속

**이산 확률 변수**:
- 확률질량함수 (PMF): $p_X(k) = P(X = k)$
- $\sum_k p_X(k) = 1$
- $F_X(x) = \sum_{k \leq x} p_X(k)$

**연속 확률 변수**:
- 확률밀도함수 (PDF): $f_X(x)$ where $P(a \leq X \leq b) = \int_a^b f_X(x)\,dx$
- $\int_{-\infty}^{\infty} f_X(x)\,dx = 1$
- $F_X(x) = \int_{-\infty}^x f_X(t)\,dt$
- $f_X(x) = \frac{dF_X}{dx}$ (거의 모든 곳에서)

---

## 3. 기댓값과 분산

### 3.1 기댓값 (Expectation)

**정의**:
- 이산: $\mathbb{E}[X] = \sum_k k \cdot p_X(k)$
- 연속: $\mathbb{E}[X] = \int_{-\infty}^{\infty} x f_X(x)\,dx$

**함수의 기댓값 (LOTUS - Law of the Unconscious Statistician)**:
$$
\mathbb{E}[g(X)] = \sum_k g(k) p_X(k) \quad \text{or} \quad \int_{-\infty}^{\infty} g(x) f_X(x)\,dx
$$

**성질 (선형성)**:
$$
\mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y]
$$

### 3.2 분산과 표준편차

**정의**:
$$
\operatorname{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
$$

**표준편차**: $\sigma_X = \sqrt{\operatorname{Var}(X)}$

**성질**:
- $\operatorname{Var}(aX + b) = a^2 \operatorname{Var}(X)$
- $\operatorname{Var}(X + Y) = \operatorname{Var}(X) + \operatorname{Var}(Y) + 2\operatorname{Cov}(X, Y)$

### 3.3 공분산과 상관계수

**공분산**:
$$
\operatorname{Cov}(X, Y) = \mathbb{E}[(X - \mathbb{E}[X])(Y - \mathbb{E}[Y])] = \mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]
$$

**상관계수**:
$$
\rho_{XY} = \frac{\operatorname{Cov}(X, Y)}{\sigma_X \sigma_Y} \in [-1, 1]
$$

**독립이면**: $\operatorname{Cov}(X, Y) = 0$ (역은 성립 안 함!)

---

## 4. 조건부 확률

### 4.1 정의

**정의**: 사건 $B$가 주어졌을 때 $A$의 조건부 확률
$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) > 0
$$

**조건부 독립**: $P(A \cap B \mid C) = P(A \mid C) P(B \mid C)$

### 4.2 곱셈 정리

$$
P(A \cap B) = P(A \mid B) P(B) = P(B \mid A) P(A)
$$

일반화:
$$
P(A_1 \cap \cdots \cap A_n) = P(A_1) P(A_2 \mid A_1) P(A_3 \mid A_1, A_2) \cdots
$$

### 4.3 전확률 공식

**정리**: $B_1, \ldots, B_n$이 $\Omega$의 분할이면
$$
P(A) = \sum_{i=1}^n P(A \mid B_i) P(B_i)
$$

**증명**: $A = \bigcup_i (A \cap B_i)$이고 서로 배타적이므로 가법성 적용. ∎

---

## 5. 베이즈 정리

### 5.1 베이즈 정리

**정리**:
$$
P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}
$$

전확률 공식과 결합:
$$
P(A_i \mid B) = \frac{P(B \mid A_i) P(A_i)}{\sum_j P(B \mid A_j) P(A_j)}
$$

**용어**:
- $P(A)$: 사전확률 (prior)
- $P(B \mid A)$: 우도 (likelihood)
- $P(A \mid B)$: 사후확률 (posterior)
- $P(B)$: 증거 (evidence)

### 5.2 예제

**예제 (의학 검사)**:
- 질병 유병률: $P(D) = 0.01$
- 검사 민감도: $P(+ \mid D) = 0.99$
- 검사 특이도: $P(- \mid D^c) = 0.95$ → $P(+ \mid D^c) = 0.05$

양성 판정 시 실제 질병 확률:
$$
P(D \mid +) = \frac{P(+ \mid D) P(D)}{P(+ \mid D) P(D) + P(+ \mid D^c) P(D^c)}
$$
$$
= \frac{0.99 \times 0.01}{0.99 \times 0.01 + 0.05 \times 0.99} = \frac{0.0099}{0.0594} \approx 0.167
$$

**놀라운 결과**: 양성이어도 실제 질병 확률은 16.7%뿐!

---

## 6. 주요 이산 분포

### 6.1 베르누이 (Bernoulli)

**PMF**: $X \in \{0, 1\}$
$$
P(X = 1) = p, \quad P(X = 0) = 1 - p
$$

**기댓값**: $\mathbb{E}[X] = p$
**분산**: $\operatorname{Var}(X) = p(1 - p)$

**딥러닝**: 이진 분류의 출력

### 6.2 이항 (Binomial)

**PMF**: $X = $ 성공 횟수 ($n$번 시행, 성공 확률 $p$)
$$
P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}
$$

**기댓값**: $np$
**분산**: $np(1-p)$

### 6.3 포아송 (Poisson)

**PMF**: 드문 사건의 발생 횟수
$$
P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}, \quad k = 0, 1, 2, \ldots
$$

**기댓값**: $\lambda$
**분산**: $\lambda$

**응용**: 단위 시간당 도착 횟수, 희귀 사건 모델링

---

## 7. 주요 연속 분포

### 7.1 균등 (Uniform)

**PDF**: $X \sim U(a, b)$
$$
f_X(x) = \frac{1}{b - a}, \quad a \leq x \leq b
$$

**기댓값**: $\frac{a + b}{2}$
**분산**: $\frac{(b - a)^2}{12}$

### 7.2 정규 (Normal / Gaussian)

**PDF**: $X \sim N(\mu, \sigma^2)$
$$
f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x - \mu)^2}{2\sigma^2} \right)
$$

**표준 정규**: $Z \sim N(0, 1)$

**68-95-99.7 규칙**:
- $P(\mu - \sigma \leq X \leq \mu + \sigma) \approx 0.68$
- $P(\mu - 2\sigma \leq X \leq \mu + 2\sigma) \approx 0.95$
- $P(\mu - 3\sigma \leq X \leq \mu + 3\sigma) \approx 0.997$

### 7.3 지수 (Exponential)

**PDF**: $X \sim \text{Exp}(\lambda)$
$$
f_X(x) = \lambda e^{-\lambda x}, \quad x \geq 0
$$

**기댓값**: $1/\lambda$
**분산**: $1/\lambda^2$

**무기억성**: $P(X > s + t \mid X > s) = P(X > t)$

**응용**: 고장 시간, 대기 시간

---

## 8. 다변량 정규분포

### 8.1 정의

**PDF**: $\mathbf{X} \sim N(\boldsymbol{\mu}, \Sigma)$, $\mathbf{X} \in \mathbb{R}^d$
$$
f_{\mathbf{X}}(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} |\Sigma|^{1/2}} \exp\left( -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^\top \Sigma^{-1} (\mathbf{x} - \boldsymbol{\mu}) \right)
$$

- $\boldsymbol{\mu} \in \mathbb{R}^d$: 평균 벡터
- $\Sigma \in \mathbb{R}^{d \times d}$: 공분산 행렬 (대칭, 양정부)

### 8.2 공분산 행렬

$$
\Sigma_{ij} = \operatorname{Cov}(X_i, X_j) = \mathbb{E}[(X_i - \mu_i)(X_j - \mu_j)]
$$

**성질**:
- 대각 성분: $\Sigma_{ii} = \operatorname{Var}(X_i)$
- 독립이면: $\Sigma$는 대각 행렬

### 8.3 고유분해와 PCA

$$
\Sigma = Q \Lambda Q^\top
$$

- $Q$의 열: 주축 방향 (PCA 주성분)
- $\Lambda$의 대각: 분산 (고유값)

**딥러닝 연결**: VAE의 latent space, Gaussian process

---

## 9. PyTorch 실습

```python
import torch
from torch.distributions import Bernoulli, Binomial, Normal, MultivariateNormal

# 1. 베르누이
bern = Bernoulli(torch.tensor(0.3))
samples = bern.sample((10000,))
print(f"경험적 평균: {samples.float().mean().item():.3f} (이론: 0.3)")

# 2. 이항
binom = Binomial(total_count=10, probs=torch.tensor(0.3))
samples = binom.sample((10000,))
print(f"경험적 평균: {samples.mean().item():.2f} (이론: {10*0.3})")
print(f"경험적 분산: {samples.var().item():.2f} (이론: {10*0.3*0.7:.2f})")

# 3. 정규분포
normal = Normal(loc=torch.tensor(0.0), scale=torch.tensor(1.0))
samples = normal.sample((100000,))
print(f"평균: {samples.mean().item():.3f}")
print(f"표준편차: {samples.std().item():.3f}")

# 68% 규칙 확인
within_1std = ((samples >= -1) & (samples <= 1)).float().mean()
print(f"[-1, 1] 내 비율: {within_1std.item():.3f} (이론: 0.68)")

# 4. 다변량 정규분포
mu = torch.tensor([0.0, 0.0])
cov = torch.tensor([[1.0, 0.5], [0.5, 1.0]])
mvn = MultivariateNormal(mu, cov)

samples = mvn.sample((10000,))
empirical_mean = samples.mean(dim=0)
empirical_cov = torch.cov(samples.T)

print(f"경험적 평균: {empirical_mean}")
print(f"경험적 공분산:\n{empirical_cov}")

# 5. 베이즈 정리 시뮬레이션
# P(D) = 0.01, P(+|D) = 0.99, P(+|D^c) = 0.05
n_trials = 100000
has_disease = torch.rand(n_trials) < 0.01

test_positive = torch.zeros(n_trials, dtype=torch.bool)
test_positive[has_disease] = torch.rand(has_disease.sum()) < 0.99
test_positive[~has_disease] = torch.rand((~has_disease).sum()) < 0.05

# P(D | +)
posterior = has_disease[test_positive].float().mean()
print(f"P(D|+) 경험적: {posterior.item():.3f} (이론: 0.167)")

# 6. 공분산과 독립성
x = torch.randn(10000)
y = x + torch.randn(10000) * 0.5  # 종속

cov_xy = torch.cov(torch.stack([x, y]))
corr_xy = cov_xy[0, 1] / (x.std() * y.std())
print(f"상관계수: {corr_xy.item():.3f}")

# 독립인 경우
y_indep = torch.randn(10000)
cov_indep = torch.cov(torch.stack([x, y_indep]))
corr_indep = cov_indep[0, 1] / (x.std() * y_indep.std())
print(f"독립 시 상관계수: {corr_indep.item():.3f} (≈ 0)")
```

---

## 10. 연습 문제

1. **조건부 확률**
   $P(A) = 0.6$, $P(B) = 0.7$, $P(A \cap B) = 0.5$일 때, $P(A \mid B)$와 $P(B \mid A)$를 구하라.

2. **베이즈 정리**
   스팸 필터: $P(\text{spam}) = 0.2$, $P(\text{"free"} \mid \text{spam}) = 0.8$, $P(\text{"free"} \mid \text{ham}) = 0.1$. "free"가 포함된 메일이 스팸일 확률은?

3. **기댓값과 분산**
   $X \sim \text{Bin}(10, 0.3)$일 때, $\mathbb{E}[X]$, $\operatorname{Var}(X)$, $\mathbb{E}[X^2]$를 구하라.

4. **정규분포**
   $X \sim N(100, 15^2)$일 때, $P(85 \leq X \leq 115)$를 표준정규표를 이용하여 구하라.

5. **다변량 정규**
   $\Sigma = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}$의 고유값과 고유벡터를 구하고, 이것이 데이터 분산 방향을 어떻게 나타내는지 설명하라.

---

## 11. 참고 자료

- Sheldon Ross, *A First Course in Probability*
- DeGroot & Schervish, *Probability and Statistics*
- Blitzstein & Hwang, *Introduction to Probability*
- MIT OCW 6.041 Probabilistic Systems Analysis

---

## 12. 다음 학습

- [[Math/Probability/3. 통계적 추론|통계 추정과 추론]]
- [[Math/Probability/4. 정보 이론|정보 이론]]
- [[Math/Probability/1. 확률과 통계 입문|확률통계 전체 개요]]
- [[ML Foundations/2. 손실 함수와 평가 지표|손실 함수와 평가]]
