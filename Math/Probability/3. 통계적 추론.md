## TL;DR
- 통계 추론(Statistical Inference)은 표본 데이터로부터 모집단 분포와 파라미터를 추정하고 가설을 검증하는 과정이다.
- MLE(최대우도추정)와 MAP(최대사후확률)는 딥러닝 학습의 이론적 토대이며, 신뢰구간과 가설 검정은 모델 평가의 통계적 근거를 제공한다.
- 중심극한정리, 불편추정량, Fisher 정보 등은 추정의 품질과 효율성을 분석하는 핵심 개념이다.

---

## 1. 표본 추정

### 1.1 표본과 통계량

**모집단 vs 표본**:
- 모집단(Population): 관심 대상 전체
- 표본(Sample): 모집단에서 추출한 일부 $X_1, \ldots, X_n$

**통계량(Statistic)**: 표본의 함수 $T(X_1, \ldots, X_n)$

**예**: 표본 평균, 표본 분산

### 1.2 표본 평균과 표본 분산

**표본 평균**:
$$
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i
$$

**표본 분산** (불편 추정량):
$$
S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
$$

왜 $n-1$? **베셀 보정(Bessel's correction)** - 자유도 보정으로 불편성 확보.

### 1.3 추정량의 성질

**불편성(Unbiasedness)**:
$$
\mathbb{E}[\hat{\theta}] = \theta
$$

**일치성(Consistency)**:
$$
\hat{\theta}_n \xrightarrow{P} \theta \quad \text{as } n \to \infty
$$

**효율성(Efficiency)**: 분산이 가장 작은 불편 추정량

---

## 2. 중심극한정리

### 2.1 대수의 법칙

**약한 대수의 법칙(Weak Law of Large Numbers)**:
$$
\bar{X}_n \xrightarrow{P} \mu \quad \text{as } n \to \infty
$$

표본 평균이 모평균으로 수렴.

**강한 대수의 법칙**:
$$
P\left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1
$$

### 2.2 중심극한정리 (CLT)

**정리**: $X_1, \ldots, X_n$ i.i.d., $\mathbb{E}[X_i] = \mu$, $\operatorname{Var}(X_i) = \sigma^2 < \infty$이면
$$
\frac{\bar{X}_n - \mu}{\sigma / \sqrt{n}} \xrightarrow{d} N(0, 1)
$$

**의미**: $n$이 충분히 크면 표본 평균은 근사적으로 정규분포
$$
\bar{X}_n \sim N\left( \mu, \frac{\sigma^2}{n} \right)
$$

**딥러닝 연결**:
- Batch gradient의 분산이 $O(1/n)$으로 감소
- 배치 크기 증가 → gradient 추정 안정화

---

## 3. 최대우도추정 (MLE)

### 3.1 우도 함수

**우도(Likelihood)**: 파라미터 $\theta$에 대한 데이터 $\mathbf{x} = (x_1, \ldots, x_n)$의 가능성
$$
L(\theta; \mathbf{x}) = \prod_{i=1}^n f(x_i; \theta)
$$

**로그우도**:
$$
\ell(\theta) = \log L(\theta) = \sum_{i=1}^n \log f(x_i; \theta)
$$

### 3.2 MLE 정의

**정의**: 우도를 최대화하는 $\theta$
$$
\hat{\theta}_{\text{MLE}} = \arg\max_{\theta} L(\theta; \mathbf{x}) = \arg\max_{\theta} \ell(\theta)
$$

**1차 조건**:
$$
\frac{\partial \ell}{\partial \theta} = 0
$$

### 3.3 예제

**예제 1 (정규분포)**:
$X_1, \ldots, X_n \sim N(\mu, \sigma^2)$ i.i.d., $\sigma^2$ 알려짐

로그우도:
$$
\ell(\mu) = -\frac{n}{2}\log(2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (x_i - \mu)^2
$$

미분:
$$
\frac{\partial \ell}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^n (x_i - \mu) = 0
$$

$$
\hat{\mu}_{\text{MLE}} = \frac{1}{n}\sum_{i=1}^n x_i = \bar{x}
$$

**예제 2 (베르누이)**:
$X_1, \ldots, X_n \sim \text{Bernoulli}(p)$

$$
L(p) = \prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} = p^{\sum x_i}(1-p)^{n - \sum x_i}
$$

$$
\ell(p) = \left(\sum x_i\right) \log p + \left(n - \sum x_i\right) \log(1-p)
$$

$$
\hat{p}_{\text{MLE}} = \frac{1}{n}\sum_{i=1}^n x_i
$$

### 3.4 MLE의 성질

**점근적 정규성**:
$$
\sqrt{n}(\hat{\theta}_{\text{MLE}} - \theta_0) \xrightarrow{d} N(0, I(\theta_0)^{-1})
$$

여기서 $I(\theta)$는 Fisher 정보.

**딥러닝 연결**: 신경망 학습은 negative log-likelihood 최소화
$$
\min_{\theta} -\sum_{i=1}^n \log p(y_i \mid x_i; \theta)
$$

---

## 4. 베이지안 추정

### 4.1 사전분포와 사후분포

**베이즈 정리**:
$$
p(\theta \mid \mathbf{x}) = \frac{p(\mathbf{x} \mid \theta) p(\theta)}{p(\mathbf{x})}
$$

- $p(\theta)$: 사전분포 (prior)
- $p(\mathbf{x} \mid \theta)$: 우도 (likelihood)
- $p(\theta \mid \mathbf{x})$: 사후분포 (posterior)
- $p(\mathbf{x}) = \int p(\mathbf{x} \mid \theta) p(\theta)\,d\theta$: 증거 (evidence)

### 4.2 최대사후확률 (MAP)

**정의**:
$$
\hat{\theta}_{\text{MAP}} = \arg\max_{\theta} p(\theta \mid \mathbf{x}) = \arg\max_{\theta} \left[ \log p(\mathbf{x} \mid \theta) + \log p(\theta) \right]
$$

**MLE vs MAP**:
- MLE: $\arg\max_{\theta} \log p(\mathbf{x} \mid \theta)$
- MAP: $\arg\max_{\theta} [\log p(\mathbf{x} \mid \theta) + \log p(\theta)]$

MAP = MLE + regularization (사전분포가 정규화 역할)

### 4.3 예제 (정규 사전분포)

$X_i \sim N(\mu, \sigma^2)$, $\mu \sim N(\mu_0, \sigma_0^2)$ (사전분포)

사후분포:
$$
\mu \mid \mathbf{x} \sim N\left( \frac{\sigma^2 \mu_0 + n\sigma_0^2 \bar{x}}{\sigma^2 + n\sigma_0^2}, \frac{\sigma^2 \sigma_0^2}{\sigma^2 + n\sigma_0^2} \right)
$$

**MAP 추정**:
$$
\hat{\mu}_{\text{MAP}} = \frac{\sigma^2 \mu_0 + n\sigma_0^2 \bar{x}}{\sigma^2 + n\sigma_0^2}
$$

사전 믿음과 데이터의 가중 평균!

---

## 5. 신뢰구간

### 5.1 정의

**$100(1-\alpha)\%$ 신뢰구간**: 무작위 구간 $[L, U]$가
$$
P(\theta \in [L, U]) = 1 - \alpha
$$

**주의**: "$\theta$가 구간 안에 있을 확률"이 아니라, "구간이 $\theta$를 포함할 확률"

### 5.2 정규분포의 신뢰구간

$X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, $\sigma^2$ 알려짐

CLT에 의해:
$$
\frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0, 1)
$$

95% 신뢰구간:
$$
\left[ \bar{x} - 1.96 \frac{\sigma}{\sqrt{n}}, \; \bar{x} + 1.96 \frac{\sigma}{\sqrt{n}} \right]
$$

**$\sigma^2$ 모를 때**: $t$-분포 사용
$$
\frac{\bar{X} - \mu}{S/\sqrt{n}} \sim t_{n-1}
$$

---

## 6. 가설 검정

### 6.1 기본 개념

**귀무가설** $H_0$ vs **대립가설** $H_1$

**예**: $H_0: \mu = \mu_0$ vs $H_1: \mu \neq \mu_0$

**오류**:
- **Type I 오류**: $H_0$가 참인데 기각 (false positive), 확률 $\alpha$ (유의수준)
- **Type II 오류**: $H_0$가 거짓인데 기각 못함 (false negative), 확률 $\beta$

**검정력(Power)**: $1 - \beta$ (진실을 발견할 확률)

### 6.2 $p$-value

**정의**: 귀무가설이 참일 때, 관측된 것보다 극단적인 결과가 나올 확률

**판정**:
- $p < \alpha$ → $H_0$ 기각
- $p \geq \alpha$ → $H_0$ 기각 못함

### 6.3 예제 ($z$-test)

$X_1, \ldots, X_n \sim N(\mu, \sigma^2)$, $H_0: \mu = \mu_0$

검정 통계량:
$$
Z = \frac{\bar{X} - \mu_0}{\sigma/\sqrt{n}} \sim N(0, 1) \quad \text{under } H_0
$$

양측 검정 ($H_1: \mu \neq \mu_0$):
- $|Z| > z_{\alpha/2}$ → 기각
- $p$-value: $2P(Z > |z_{\text{obs}}|)$

---

## 7. Fisher 정보

### 7.1 정의

**Fisher 정보**:
$$
I(\theta) = \mathbb{E}\left[ \left( \frac{\partial \log f(X; \theta)}{\partial \theta} \right)^2 \right] = -\mathbb{E}\left[ \frac{\partial^2 \log f(X; \theta)}{\partial \theta^2} \right]
$$

**의미**: 데이터가 $\theta$에 대해 제공하는 정보량

### 7.2 Cramér-Rao 하한

**정리**: 불편 추정량 $\hat{\theta}$의 분산은
$$
\operatorname{Var}(\hat{\theta}) \geq \frac{1}{nI(\theta)}
$$

**의미**: 어떤 불편 추정량도 이보다 작은 분산을 가질 수 없음

**효율성**: $\operatorname{Var}(\hat{\theta}) = \frac{1}{nI(\theta)}$이면 효율적

**MLE**: 점근적으로 효율적!

---

## 8. PyTorch 실습

```python
import torch
import numpy as np
from scipy import stats

# 1. 중심극한정리 시각화
def clt_demo(dist_fn, n_samples, n_trials=10000):
    means = []
    for _ in range(n_trials):
        sample = dist_fn(n_samples)
        means.append(sample.mean().item())

    means = torch.tensor(means)
    print(f"표본 평균의 평균: {means.mean().item():.3f}")
    print(f"표본 평균의 std: {means.std().item():.3f}")
    return means

# 지수분포 (λ=1, 평균=1, std=1)
exponential_samples = lambda n: -torch.log(torch.rand(n))

# n=5
means_5 = clt_demo(exponential_samples, n_samples=5)
# n=30
means_30 = clt_demo(exponential_samples, n_samples=30)
# 이론: std = 1/sqrt(n)

# 2. MLE (정규분포 평균)
true_mu, true_sigma = 5.0, 2.0
data = torch.randn(1000) * true_sigma + true_mu

mu_mle = data.mean()
sigma_mle = data.std(unbiased=True)

print(f"True: μ={true_mu}, σ={true_sigma}")
print(f"MLE: μ={mu_mle.item():.3f}, σ={sigma_mle.item():.3f}")

# 3. MAP (정규 사전분포)
# Prior: μ ~ N(0, 10)
prior_mu, prior_sigma = 0.0, 10.0
n = len(data)
x_bar = data.mean().item()
sigma = 2.0  # 가정

# Posterior mean (MAP)
posterior_var = 1 / (1/prior_sigma**2 + n/sigma**2)
posterior_mean = posterior_var * (prior_mu/prior_sigma**2 + n*x_bar/sigma**2)

print(f"MAP: μ={posterior_mean:.3f}")
print(f"MLE: μ={x_bar:.3f}")

# 4. 신뢰구간
confidence = 0.95
alpha = 1 - confidence
z_critical = stats.norm.ppf(1 - alpha/2)

margin = z_critical * sigma / np.sqrt(n)
ci_lower = x_bar - margin
ci_upper = x_bar + margin

print(f"95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]")
print(f"True μ={true_mu} in CI: {ci_lower <= true_mu <= ci_upper}")

# 5. 가설 검정 (z-test)
mu_0 = 5.0  # H0: μ = 5
z_stat = (x_bar - mu_0) / (sigma / np.sqrt(n))
p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print(f"Z-statistic: {z_stat:.3f}")
print(f"p-value: {p_value:.4f}")
print(f"Reject H0 (α=0.05): {p_value < 0.05}")

# 6. Fisher 정보 (정규분포)
# I(μ) = 1/σ²
fisher_info = 1 / sigma**2
cramer_rao_bound = 1 / (n * fisher_info)

print(f"Cramér-Rao 하한: {cramer_rao_bound:.4f}")
print(f"표본 평균 분산: {(sigma**2 / n):.4f}")
# 같음! → 표본 평균은 효율적
```

---

## 9. 연습 문제

1. **MLE**
   $X_1, \ldots, X_n \sim \text{Exp}(\lambda)$일 때, $\lambda$의 MLE를 구하라.

2. **MAP vs MLE**
   $X \sim N(\mu, 1)$ 1개 관측, 사전분포 $\mu \sim N(0, 1)$. MLE와 MAP를 비교하라.

3. **신뢰구간**
   $n=25$, $\bar{x}=100$, $s=15$일 때, $\mu$의 95% 신뢰구간을 구하라 ($t$-분포 사용).

4. **가설 검정**
   $H_0: \mu = 50$ vs $H_1: \mu > 50$. $n=100$, $\bar{x}=52$, $\sigma=10$. 유의수준 5%에서 검정하라.

5. **Cramér-Rao**
   베르누이($p$)의 Fisher 정보를 계산하고, 표본 비율 $\hat{p} = \bar{X}$가 효율적임을 보여라.

---

## 10. 참고 자료

- Casella & Berger, *Statistical Inference*, 2nd ed.
- Larry Wasserman, *All of Statistics*
- Kevin P. Murphy, *Probabilistic Machine Learning*
- MIT OCW 18.650 Statistics for Applications

---

## 11. 다음 학습

- [[Math/Probability/4. 정보 이론|정보 이론]]
- [[Math/Probability/2. 확률 기초|확률 기초]]
- [[ML Foundations/2. 손실 함수와 평가 지표|손실 함수]] (MLE 연결)
- [[ML Foundations/4. 정규화와 일반화|정규화]] (MAP 연결)
