## TL;DR
- 컨볼루션(convolution)은 입력의 국소 영역에 동일한 가중치를 적용해 출력을 생성하는 선형 연산이며, CNN에서 패턴을 감지하는 핵심 메커니즘이다.
- 커널 크기, stride, padding, dilation, group 설정에 따라 receptive field와 연산량이 달라진다.
- 시간/공간 도메인뿐 아니라 주파수 도메인(Fourier 변환)에서의 관점을 이해하면 필터 설계와 가속화(FFT) 전략을 세울 수 있다.

## 핵심 개념
- **이산 컨볼루션 정의**
  - 1D: `(f * g)[n] = Σ_k f[k] g[n - k]`
  - 2D 이미지: `(K * X)(i, j) = Σ_{m,n} K(m, n) X(i - m, j - n)`
  - PyTorch `nn.Conv2d`는 correlation(커널을 뒤집지 않은 형태)을 구현하므로 학습 가능한 필터에서는 차이가 없다.
- **가중치 공유와 이동 불변성**
  - 동일한 커널이 전체 입력 위치에 적용 → 파라미터 수 감소, 번역 변환에 대해 동일한 패턴 인식.
- **출력 크기 계산**
  - 2D 기준: `H_out = ⌊(H_in + 2P - D (K - 1) - 1) / S⌋ + 1`
  - `Kernel(K)`, `Stride(S)`, `Padding(P)`, `Dilation(D)` 등 하이퍼파라미터가 출력 크기와 receptive field에 직접 영향.
- **Group과 Depthwise Convolution**
  - group=1 → 일반 conv, group=채널 수 → depthwise(conv per channel).
  - depthwise + pointwise(1×1) = depthwise-separable, 연산량 크게 절약(MobileNet 등).
- **Convolution Theorem**
  - `F{f * g} = F{f} · F{g}` → 시간 도메인에서의 컨볼루션은 주파수 도메인에서의 곱셈.
  - FFT 기반 컨볼루션은 큰 커널 또는 긴 시퀀스를 처리할 때 효율적.
- **경계 처리**
  - padding 종류: zero, reflection, replication. `same` 패딩은 출력 크기를 입력과 동일하게 유지.

## PyTorch 실습
```python
import torch
import torch.nn.functional as F

x = torch.arange(16, dtype=torch.float32).view(1, 1, 4, 4)
kernel = torch.tensor([[1., 0.], [0., -1.]]).view(1, 1, 2, 2)

out_valid = F.conv2d(x, kernel, padding=0, stride=1)
out_same = F.conv2d(x, kernel, padding=1, stride=1)

print("valid shape:", out_valid.shape, "\n", out_valid)
print("same shape:", out_same.shape, "\n", out_same)
```
- padding=0은 valid convolution, padding=1은 same convolution 효과(출력 4×4 유지).
- 커널을 학습시키면 edge detector, blur, sharpen 등 다양한 필터를 자동으로 학습하게 된다.

## FFT 기반 컨볼루션
```python
import numpy as np

def fft_convolve(signal, kernel):
    n = len(signal) + len(kernel) - 1
    fft_size = 2 ** int(np.ceil(np.log2(n)))
    F_signal = np.fft.rfft(signal, fft_size)
    F_kernel = np.fft.rfft(kernel, fft_size)
    conv = np.fft.irfft(F_signal * F_kernel, fft_size)
    return conv[:n]
```
- 큰 커널(예: 오디오 필터링, NLP의 긴 시퀀스)에서는 FFT 기반 컨볼루션이 `O(n log n)`으로 효율적이다.

## 실습 포인트
- 서로 다른 커널 크기/stride/dilation 조합으로 PyTorch `Conv2d`를 실험하고 출력 크기를 표로 정리.
- depthwise 및 depthwise-separable convolution을 구현해 연산량( FLOPs )과 파라미터 수를 비교.
- FFT 컨볼루션과 직접 컨볼루션(`scipy.signal.convolve`)의 실행 시간을 입력 크기에 따라 비교.
- Edge detection 커널(예: Sobel)을 직접 정의해 이미지에 적용한 후 시각적으로 확인.

## 추천 참고 자료
- Stanford CS231n Convolutional Neural Networks 강의 노트
- *Signal Processing and Linear Systems* (B. P. Lathi)
- FFT 기반 Conv 논문: *Fast Algorithms for Convolutional Neural Networks* (Lavin & Gray, 2016)

## 다음 학습
- [[Operators/2. 행렬 분해]]
- [[Modeling/Custom Blocks]]
- [[Projects/Image Classification Pipeline]]
- [[Math/Analysis/2. 푸리에 변환]]
