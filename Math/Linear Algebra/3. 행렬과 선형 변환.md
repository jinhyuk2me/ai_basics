## TL;DR
- 행렬(Matrix)은 선형 변환(Linear Transformation)을 표현하는 도구로, 딥러닝의 모든 층(layer)은 본질적으로 행렬 연산이다.
- 행렬 곱셈은 변환의 합성을 의미하며, 역행렬은 변환을 되돌리는 연산이다.
- 행렬식(Determinant)은 변환이 공간의 부피를 얼마나 확대/축소하는지 측정하며, 역행렬 존재 여부를 판별하는 핵심 도구다.

---

## 1. 선형 변환

### 1.1 선형 변환의 정의

**정의 (선형 변환)**: 벡터 공간 $V, W$ 사이의 함수 $T: V \rightarrow W$가 다음을 만족하면 선형 변환(linear transformation) 또는 선형 사상이라 한다:
1. **가법성**: $T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$
2. **동차성**: $T(c\mathbf{v}) = cT(\mathbf{v})$

이 두 조건을 합쳐서 다음과 같이 쓸 수 있다:
$$
T(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2) = c_1 T(\mathbf{v}_1) + c_2 T(\mathbf{v}_2)
$$

**핵심**: 선형 변환은 "직선을 직선으로, 원점을 원점으로" 보낸다.

### 1.2 선형 변환의 예시

**예제 1 (회전)**: $\mathbb{R}^2$에서 원점 중심 반시계 방향 $\theta$ 회전
$$
T\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}
$$

**예제 2 (스케일링)**: 각 좌표를 $k$배
$$
T\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} kx \\ ky \end{pmatrix}
$$

**예제 3 (투영)**: $\mathbb{R}^3$에서 xy-평면으로 투영
$$
T\begin{pmatrix} x \\ y \\ z \end{pmatrix} = \begin{pmatrix} x \\ y \\ 0 \end{pmatrix}
$$

**비예제 (평행이동)**: $T(\mathbf{x}) = \mathbf{x} + \mathbf{b}$ (단, $\mathbf{b} \neq \mathbf{0}$)
- 원점이 원점으로 가지 않으므로 선형 변환이 아니다.
- 딥러닝의 affine 변환 $y = Wx + b$는 선형 + 평행이동.

### 1.3 행렬 표현

**정리**: $T: \mathbb{R}^n \rightarrow \mathbb{R}^m$이 선형 변환이면, 유일한 $m \times n$ 행렬 $A$가 존재하여
$$
T(\mathbf{x}) = A\mathbf{x}
$$

**구성 방법**: $\mathbf{e}_1, \ldots, \mathbf{e}_n$을 $\mathbb{R}^n$의 표준 기저라 하면,
$$
A = [T(\mathbf{e}_1) \mid T(\mathbf{e}_2) \mid \cdots \mid T(\mathbf{e}_n)]
$$

**예제**: 회전 변환 $T(\mathbf{e}_1) = (\cos\theta, \sin\theta)$, $T(\mathbf{e}_2) = (-\sin\theta, \cos\theta)$이므로
$$
A = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}
$$

---

## 2. 행렬 연산

### 2.1 행렬 덧셈과 스칼라 곱

**행렬 덧셈**: $(A + B)_{ij} = A_{ij} + B_{ij}$
- 같은 크기의 행렬만 더할 수 있다.

**스칼라 곱**: $(cA)_{ij} = c \cdot A_{ij}$

**성질**:
- 교환법칙: $A + B = B + A$
- 결합법칙: $(A + B) + C = A + (B + C)$
- 분배법칙: $c(A + B) = cA + cB$

### 2.2 행렬 곱셈

**정의**: $A \in \mathbb{R}^{m \times n}$, $B \in \mathbb{R}^{n \times p}$에 대해
$$
(AB)_{ij} = \sum_{k=1}^n A_{ik} B_{kj}
$$

**기하학적 의미**: 행렬 곱 $AB$는 변환 $B$를 먼저 적용하고 $A$를 적용하는 **합성 변환**이다:
$$
T_{AB}(\mathbf{x}) = T_A(T_B(\mathbf{x}))
$$

**성질**:
- **결합법칙**: $(AB)C = A(BC)$
- **분배법칙**: $A(B + C) = AB + AC$
- **비교환**: 일반적으로 $AB \neq BA$

**예제**: 회전 후 스케일링
$$
\underbrace{\begin{bmatrix} 2 & 0 \\ 0 & 2 \end{bmatrix}}_{\text{스케일}} \underbrace{\begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}}_{\text{회전}}
$$
순서를 바꾸면 결과가 다르다!

### 2.3 전치 행렬

**정의**: $A^\top$의 $(i, j)$ 성분은 $A$의 $(j, i)$ 성분이다:
$$
(A^\top)_{ij} = A_{ji}
$$

**성질**:
- $(A^\top)^\top = A$
- $(A + B)^\top = A^\top + B^\top$
- $(AB)^\top = B^\top A^\top$ (순서 주의!)
- $(cA)^\top = cA^\top$

**대칭 행렬**: $A = A^\top$인 행렬. 공분산 행렬, Hessian이 대표적 예시.

---

## 3. 역행렬과 가역성

### 3.1 역행렬의 정의

**정의**: 정사각 행렬 $A \in \mathbb{R}^{n \times n}$에 대해 $AB = BA = I$를 만족하는 행렬 $B$가 존재하면, $A$를 가역(invertible)이라 하고 $B = A^{-1}$로 표기한다.

### 3.2 역행렬 존재 조건

**정리**: 다음은 동치이다:
1. $A$가 가역이다
2. $\det(A) \neq 0$
3. $\operatorname{rank}(A) = n$
4. $A$의 열벡터들이 선형 독립
5. $A\mathbf{x} = \mathbf{0}$의 해가 $\mathbf{x} = \mathbf{0}$뿐
6. $A$의 고유값이 모두 0이 아니다. ([[4. 고유값과 고유벡터]])

### 3.3 2×2 역행렬 공식

$$
A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}
\Rightarrow
A^{-1} = \frac{1}{\det(A)} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
$$
단, $\det(A) = ad - bc \neq 0$

**예제**:
$$
A = \begin{bmatrix} 2 & 1 \\ 5 & 3 \end{bmatrix}, \quad
\det(A) = 6 - 5 = 1
$$
$$
A^{-1} = \begin{bmatrix} 3 & -1 \\ -5 & 2 \end{bmatrix}
$$

검증:
$$
AA^{-1} = \begin{bmatrix} 2 & 1 \\ 5 & 3 \end{bmatrix} \begin{bmatrix} 3 & -1 \\ -5 & 2 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$

### 3.4 역행렬의 성질

- $(A^{-1})^{-1} = A$
- $(AB)^{-1} = B^{-1}A^{-1}$ (순서 반대!)
- $(A^\top)^{-1} = (A^{-1})^\top$
- $\det(A^{-1}) = \frac{1}{\det(A)}$

---

## 4. 행렬식 (Determinant)

### 4.1 기하학적 의미

행렬식 $\det(A)$는:
- **부피 변환 계수**: 단위 정육면체가 $A$에 의해 변환될 때 부피가 $|\det(A)|$배 된다
- **부호**: $\det(A) < 0$이면 방향(orientation)이 뒤집힌다

**2차원 예시**:
$$
\det\begin{bmatrix} 2 & 0 \\ 0 & 3 \end{bmatrix} = 6
$$
단위 정사각형(넓이 1)이 $2 \times 3$ 직사각형(넓이 6)으로 변환.

### 4.2 정의와 계산

**2×2**:
$$
\det\begin{bmatrix} a & b \\ c & d \end{bmatrix} = ad - bc
$$

**3×3 (사루스 규칙)**:
$$
\det\begin{bmatrix}
a & b & c \\
d & e & f \\
g & h & i
\end{bmatrix}
= aei + bfg + cdh - ceg - bdi - afh
$$

**일반 $n \times n$ (라플라스 전개)**:
$$
\det(A) = \sum_{j=1}^n (-1)^{i+j} a_{ij} M_{ij}
$$
여기서 $M_{ij}$는 $i$행 $j$열을 제거한 소행렬식(minor).

### 4.3 행렬식의 성질

1. **전치**: $\det(A^\top) = \det(A)$
2. **곱**: $\det(AB) = \det(A)\det(B)$
3. **스칼라 곱**: $\det(cA) = c^n \det(A)$ (단, $A$는 $n \times n$)
4. **행 교환**: 두 행을 바꾸면 부호가 바뀜
5. **행 배수**: 한 행에 스칼라를 곱하면 행렬식도 그만큼 곱해짐
6. **행 덧셈**: 한 행에 다른 행의 배수를 더해도 행렬식 불변

**예제** (성질 6 활용):
$$
\begin{vmatrix}
1 & 2 & 3 \\
0 & 1 & 4 \\
0 & 0 & 2
\end{vmatrix}
= 1 \cdot 1 \cdot 2 = 2
$$
상삼각 행렬의 행렬식은 대각 성분의 곱.

---

## 5. 특수 행렬

### 5.1 항등 행렬 (Identity Matrix)

$$
I_n = \begin{bmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1
\end{bmatrix}
$$

- $AI = IA = A$
- $\det(I) = 1$

### 5.2 대각 행렬 (Diagonal Matrix)

$$
D = \begin{bmatrix}
d_1 & 0 & \cdots & 0 \\
0 & d_2 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & d_n
\end{bmatrix}
$$

- $\det(D) = d_1 d_2 \cdots d_n$
- 역행렬: $D^{-1} = \operatorname{diag}(1/d_1, \ldots, 1/d_n)$ (단, $d_i \neq 0$)

### 5.3 직교 행렬 (Orthogonal Matrix)

**정의**: $Q^\top Q = QQ^\top = I$를 만족하는 행렬.

**성질**:
- $Q^{-1} = Q^\top$ (역행렬 계산이 매우 쉬움!)
- $\det(Q) = \pm 1$
- 벡터의 길이와 각도를 보존: $\|Q\mathbf{x}\| = \|\mathbf{x}\|$

**예제**: 회전 행렬
$$
Q = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}
$$

**딥러닝 연결**: Orthogonal initialization, Spectral Normalization에서 사용.

### 5.4 대칭 행렬 (Symmetric Matrix)

**정의**: $A = A^\top$

**성질**:
- 모든 고유값이 실수
- 고유벡터들을 서로 직교하도록 선택 가능
- 직교 대각화 가능: $A = QDQ^\top$ (스펙트럴 정리)

**예제**: 공분산 행렬, Hessian

---

## 6. 선형 시스템

### 6.1 연립 방정식의 행렬 표현

$$
\begin{cases}
2x + y = 5 \\
x + 3y = 6
\end{cases}
\quad \Leftrightarrow \quad
\begin{bmatrix} 2 & 1 \\ 1 & 3 \end{bmatrix}
\begin{bmatrix} x \\ y \end{bmatrix}
=
\begin{bmatrix} 5 \\ 6 \end{bmatrix}
$$

일반 형태: $A\mathbf{x} = \mathbf{b}$

### 6.2 해의 존재성과 유일성

**정리**:
1. $A$가 가역이면 유일해 $\mathbf{x} = A^{-1}\mathbf{b}$ 존재
2. $\operatorname{rank}(A) < n$이면:
   - $\mathbf{b} \in \operatorname{col}(A)$이면 무수히 많은 해
   - $\mathbf{b} \notin \operatorname{col}(A)$이면 해 없음

### 6.3 Gaussian Elimination

**방법**: 행 연산(row operation)으로 행 사다리꼴(row echelon form)로 변환

**예제**:
$$
\begin{bmatrix}
2 & 1 & | & 5 \\
1 & 3 & | & 6
\end{bmatrix}
\xrightarrow{R_1 \leftrightarrow R_2}
\begin{bmatrix}
1 & 3 & | & 6 \\
2 & 1 & | & 5
\end{bmatrix}
\xrightarrow{R_2 - 2R_1}
\begin{bmatrix}
1 & 3 & | & 6 \\
0 & -5 & | & -7
\end{bmatrix}
$$

역대입: $-5y = -7 \Rightarrow y = 7/5$, $x + 3(7/5) = 6 \Rightarrow x = 9/5$

---

## 7. PyTorch 실습

```python
import torch

# 1. 선형 변환
theta = torch.tensor(torch.pi / 6)  # 30도 회전
R = torch.tensor([
    [torch.cos(theta), -torch.sin(theta)],
    [torch.sin(theta),  torch.cos(theta)]
])

v = torch.tensor([1.0, 0.0])
v_rotated = R @ v
print(f"회전 변환: {v} → {v_rotated}")

# 2. 행렬 곱셈 (변환 합성)
S = torch.tensor([[2.0, 0.0], [0.0, 2.0]])  # 스케일링
combined = S @ R  # 회전 후 스케일링
v_transformed = combined @ v
print(f"합성 변환: {v} → {v_transformed}")

# 3. 역행렬
A = torch.tensor([[2.0, 1.0], [5.0, 3.0]])
A_inv = torch.linalg.inv(A)
print(f"A의 역행렬:\n{A_inv}")
print(f"검증 AA^-1:\n{A @ A_inv}")

# 4. 행렬식
det = torch.linalg.det(A)
print(f"det(A) = {det.item()}")

# 5. 선형 시스템 풀기
b = torch.tensor([5.0, 6.0])
x = torch.linalg.solve(A, b)
print(f"Ax = b의 해: {x}")
print(f"검증 Ax = {A @ x}")

# 6. 직교 행렬 확인
Q, R = torch.linalg.qr(torch.randn(3, 3))
print(f"Q^T Q (항등행렬이어야 함):\n{Q.T @ Q}")
```

---

## 8. 연습 문제

1. **선형성 확인**
   다음 변환이 선형인지 판별하라:
   - $T(x, y) = (2x + y, x - 3y)$
   - $T(x, y) = (x^2, y)$
   - $T(x, y, z) = (x + 1, y + z)$

2. **행렬 곱셈**
   $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$, $B = \begin{bmatrix} 2 & 0 \\ 1 & 3 \end{bmatrix}$일 때,
   $AB$와 $BA$를 계산하고 왜 다른지 기하학적으로 설명하라.

3. **역행렬 계산**
   $A = \begin{bmatrix} 1 & 2 & 3 \\ 0 & 1 & 4 \\ 5 & 6 & 0 \end{bmatrix}$의 역행렬을 Gaussian elimination으로 구하라.

4. **행렬식 성질**
   $\det(A) = 5$일 때, $\det(2A)$, $\det(A^{-1})$, $\det(A^\top A)$를 구하라. (단, $A$는 $3 \times 3$)

5. **직교 행렬**
   $Q = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}$가 직교 행렬임을 증명하고, $\det(Q) = 1$임을 보여라.

6. **선형 시스템**
   다음 시스템의 해가 존재하는 $b_3$의 조건을 구하라:
   $$
   \begin{bmatrix} 1 & 2 & 3 \\ 2 & 4 & 6 \\ 1 & 2 & b_3 \end{bmatrix}
   \begin{bmatrix} x \\ y \\ z \end{bmatrix}
   =
   \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}
   $$

---

## 9. 참고 자료

- Gilbert Strang, *Introduction to Linear Algebra*, Chapter 2, 5, 6
- David C. Lay, *Linear Algebra and Its Applications*, Chapter 1-2
- MIT OCW 18.06, Lectures 3, 5, 18-20
- 3Blue1Brown, *Essence of Linear Algebra*, Episode 3-6, 8-11

---

## 10. 다음 학습

- [[Math/Linear Algebra/고유값과 고유벡터|고유값과 고유벡터]]
- [[Math/Linear Algebra/특잇값 분해|특이값 분해 (SVD)]]
- [[Math/Linear Algebra/벡터 공간과 기저|벡터 공간과 기저]]
- [[Operators/선형 연산자|선형 연산자]]
