## TL;DR
- AI는 Rule-Based AI부터 Machine Learning, 그리고 Deep Learning까지 발전해왔으며, 각각 다른 접근 방식과 응용 분야를 가집니다.
- Machine Learning은 모델 복잡도(Traditional ML vs Deep Learning)와 학습 패러다임(지도, 비지도, 강화 등)이라는 두 축으로 이해할 수 있습니다.
- 학습 패러다임은 Traditional ML과 Deep Learning 모두에 적용되는 상위 개념입니다.
- 이 분류 체계를 이해하면 새로운 문제에 어떤 접근법을 선택할지 판단할 수 있습니다.

## AI 전체 분류

### 1. Rule-Based AI (규칙 기반 AI)
명시적인 규칙과 논리로 동작하는 초기 AI 접근법

**주요 기법**
- Expert Systems (전문가 시스템)
- Symbolic AI
- Knowledge-Based Systems
- 논리 기반, If-then 규칙으로 동작

**특징**
- 도메인 전문가의 지식을 명시적 규칙으로 코딩
- 예측 가능하고 해석 가능
- 규칙 유지보수가 어렵고 확장성 제한

**응용**
- 초기 의료 진단 시스템
- 체스 프로그램 (Deep Blue 이전)

---

### 2. Machine Learning (머신러닝)

데이터로부터 패턴을 학습하는 AI

#### [축 1] 모델 복잡도별 분류

##### 2.1 Traditional Machine Learning (전통적 머신러닝)

얕은 구조의 학습 모델

**주요 알고리즘**
- Linear/Logistic Regression
- Decision Tree, Random Forest
- SVM (Support Vector Machine)
- Naive Bayes
- KNN (K-Nearest Neighbors)
- PCA, t-SNE (차원 축소)
- K-Means, DBSCAN (클러스터링)
- Q-Learning, SARSA (전통적 강화학습)

**특징**
- 명시적 특징 공학(Feature Engineering) 필요
- 상대적으로 적은 데이터로 학습 가능
- 해석 가능성이 높음
- 복잡한 패턴 학습에 한계

**응용**
- 스팸 필터링, 신용 평가
- 고객 세분화, 추천 시스템 (초기)

##### 2.2 Deep Learning (딥러닝)

다층 신경망 기반의 머신러닝

**기본 신경망**
- MLP (Multi-Layer Perceptron)
- Feedforward Neural Networks

**CNN (Convolutional Neural Networks)**
- 이미지/비디오 처리 특화
- 모델: ResNet, VGG, EfficientNet, MobileNet
- 응용: 이미지 분류, 객체 검출, 세그멘테이션, Re-ID

**RNN 계열 (Recurrent Neural Networks)**
- RNN, LSTM, GRU
- 시퀀스 데이터 처리 (시계열, 텍스트)
- 응용: 기계 번역, 음성 인식 (초기)

**Transformer**
- Attention Mechanism 기반
- NLP: BERT, GPT, T5, LLaMA, Claude
- Vision: ViT, Swin Transformer
- Multi-modal: CLIP, GPT-4V, Gemini
- 응용: 대화형 AI, 문서 이해, 이미지-텍스트 통합 작업

**생성 모델 (Generative Models)**
- GAN (Generative Adversarial Networks): 이미지 생성, 스타일 변환
- VAE (Variational Autoencoder): 잠재 표현 학습
- Diffusion Models: Stable Diffusion, DALL-E
- Autoregressive Models: GPT 계열
- 응용: 이미지/텍스트/음악 생성, 데이터 증강

**Graph Neural Networks**
- GCN, GAT, GraphSAGE
- 그래프 구조 데이터 처리
- 응용: 소셜 네트워크 분석, 분자 구조 예측

**Deep Reinforcement Learning**
- DQN, A3C, PPO
- AlphaGo, AlphaZero
- 응용: 게임, 로보틱스, 자율주행

**특징**
- 자동 특징 학습 (Feature Learning)
- 대규모 데이터와 컴퓨팅 자원 필요
- 복잡한 비선형 패턴 학습 가능
- 해석 가능성이 낮음 (Black Box)

---

#### [축 2] 학습 패러다임별 분류

Traditional ML과 Deep Learning 모두에 적용되는 학습 방식

##### 지도 학습 (Supervised Learning)

입력-정답 쌍 $(x, y)$로 함수 $f: x \to y$를 학습

**Traditional ML 예시**
- Logistic Regression: 이진 분류
- SVM: 비선형 분류
- Random Forest: 회귀/분류

**Deep Learning 예시**
- CNN: 이미지 분류 (ImageNet)
- Transformer: 텍스트 분류, 기계 번역

**주요 과제**
- 분류 (Classification)
- 회귀 (Regression)
- 시계열 예측
- 구조적 예측 (시퀀스 라벨링)

**응용**
- 이미지 분류, 스팸 필터링
- 주가 예측, 수요 예측
- 의료 영상 진단

**관련 노트**: [[MLDL Basic/1. 학습 패러다임]]

---

##### 비지도 학습 (Unsupervised Learning)

라벨 없이 데이터의 숨겨진 구조를 파악

**Traditional ML 예시**
- K-Means: 클러스터링
- PCA: 차원 축소
- GMM: 밀도 추정

**Deep Learning 예시**
- Autoencoder: 차원 축소, 이상 탐지
- GAN: 이미지 생성
- VAE: 잠재 표현 학습
- Diffusion Models: 고품질 생성

**주요 과제**
- 클러스터링 (Clustering)
- 차원 축소 (Dimensionality Reduction)
- 밀도 추정 (Density Estimation)
- 이상 탐지 (Anomaly Detection)

**응용**
- 고객 세분화
- 데이터 시각화
- 생성 모델링

**관련 노트**: [[MLDL Basic/1. 학습 패러다임]]

---

##### 자기지도 학습 (Self-supervised Learning)

라벨 없이 프리텍스트 태스크(Pretext Task)를 정의하여 표현 벡터를 학습

**주요 기법**
- Masked Language Modeling (MLM): BERT의 단어 마스킹 예측
- Contrastive Learning: SimCLR, MoCo (유사한 데이터는 가깝게, 다른 데이터는 멀게)
- Image Inpainting: 이미지 일부를 가리고 복원
- Rotation Prediction: 이미지 회전 각도 예측

**특징**
- 라벨링 비용 없이 대규모 데이터 활용 가능
- 사전학습(Pre-training) 후 파인튜닝(Fine-tuning)으로 다양한 태스크에 적용
- 주로 Deep Learning에서 사용

**응용**
- LLM 사전학습 (GPT, BERT)
- 이미지 표현 학습 (SimCLR)
- 멀티모달 학습 (CLIP)

**관련 노트**: [[MLDL Basic/1. 학습 패러다임]]

---

##### 반지도 학습 (Semi-supervised Learning)

소량의 라벨 데이터 + 대량의 비라벨 데이터를 동시에 활용

**주요 기법**
- Pseudo-labeling: 모델이 비라벨 데이터에 예측한 라벨을 사용
- Consistency Regularization: 입력에 노이즈를 주어도 예측이 일관되도록 학습
- Graph-based Methods: 데이터 간 유사도 그래프 활용

**특징**
- 라벨링 비용이 큰 도메인에서 유용
- 비라벨 데이터로 결정 경계를 더 명확하게 학습

**응용**
- 의료 영상 (라벨이 적음)
- 음성 인식
- 웹 크롤링 데이터 활용

**관련 노트**: [[MLDL Basic/1. 학습 패러다임]]

---

##### 강화 학습 (Reinforcement Learning)

에이전트가 환경과 상호작용하며 보상을 최대화하는 정책을 학습

**Traditional RL**
- Q-Learning: 가치 함수 기반
- SARSA: On-policy 학습
- Monte Carlo Methods

**Deep RL**
- DQN: Deep Q-Network (Atari 게임)
- PPO: Proximal Policy Optimization
- A3C: Asynchronous Advantage Actor-Critic
- AlphaGo, AlphaZero

**구성 요소**
- 상태 (State) $S$
- 행동 (Action) $A$
- 보상 (Reward) $R$
- 전이 확률 (Transition) $T$
- 정책 (Policy) $\pi$
- 가치 함수 (Value Function) $V$

**응용**
- 게임 (Atari, 바둑, 스타크래프트)
- 로보틱스 (보행, 조작)
- 추천 시스템
- 자율주행

**관련 노트**: [[MLDL Basic/1. 학습 패러다임]]

---

##### 전이 학습 (Transfer Learning)

사전학습된 모델을 새로운 태스크에 적용

**주요 방법**
- Fine-tuning: 사전학습 모델의 가중치를 새 데이터로 미세 조정
- Feature Extraction: 사전학습 모델을 고정하고 마지막 층만 학습

**특징**
- 적은 데이터로도 좋은 성능 달성
- 학습 시간 단축
- 도메인 간 지식 전이

**응용**
- ImageNet 사전학습 → 의료 영상 분류
- BERT 사전학습 → 감성 분석
- GPT 사전학습 → 특정 도메인 챗봇

---

##### Few-shot / Zero-shot Learning

소량 또는 제로 예제로 새로운 태스크 수행

**Few-shot Learning**
- 각 클래스당 1~5개 예제만으로 학습
- Meta-learning, Prototypical Networks

**Zero-shot Learning**
- 학습 시 보지 못한 클래스를 텍스트 설명만으로 예측
- CLIP: 이미지-텍스트 매칭

**특징**
- 대규모 사전학습 모델에서 주로 가능
- 프롬프트 엔지니어링과 결합

**응용**
- LLM의 In-Context Learning (GPT-4)
- 이미지 분류 (CLIP)

---

### 3. Evolutionary Algorithms (진화 알고리즘)

생물 진화 원리를 모방한 최적화 알고리즘

**주요 기법**
- Genetic Algorithms (유전 알고리즘)
- Genetic Programming
- Evolution Strategies

**특징**
- 해 공간을 탐색하며 최적해를 찾음
- 미분 불가능한 문제에도 적용 가능

**응용**
- 조합 최적화 문제
- 신경망 아키텍처 탐색 (NAS)

---

### 4. Fuzzy Logic (퍼지 논리)

불확실한 정보를 처리하는 논리 체계

**특징**
- True/False 대신 [0, 1] 범위의 소속도 사용
- 인간의 애매모호한 판단을 모델링

**응용**
- 제어 시스템 (세탁기, 에어컨)
- 의사결정 지원 시스템

---

### 5. Hybrid AI (하이브리드)

여러 AI 접근법을 결합

**Neuro-Symbolic AI**
- 신경망(학습) + 기호 논리(추론)
- 해석 가능성과 학습 능력을 동시에 추구

**Knowledge Graph + ML**
- 지식 그래프의 구조 정보 + 딥러닝

**Physics-Informed Neural Networks (PINNs)**
- 물리 법칙을 손실 함수에 포함
- 과학 시뮬레이션, 편미분방정식 해결

**Retrieval-Augmented Generation (RAG)**
- 검색 시스템 + 생성 모델
- LLM의 환각(Hallucination) 문제 완화

**응용**
- 질의응답 시스템 (RAG)
- 과학 계산 (PINNs)

---

## 분류 체계 활용법

### 문제 해결 시 접근 순서

1. **데이터 확인**
   - 라벨 유무: 지도 vs 비지도
   - 라벨 수량: 충분 → 지도, 적음 → 반지도/자기지도
   - 데이터 크기: 작음 → Traditional ML, 큼 → Deep Learning

2. **태스크 정의**
   - 분류/회귀 → 지도 학습
   - 군집화/생성 → 비지도 학습
   - 순차적 의사결정 → 강화 학습

3. **모델 선택**
   - 해석 가능성 중요 → Traditional ML
   - 성능 최우선 + 데이터 충분 → Deep Learning
   - 사전학습 모델 활용 가능 → 전이 학습

### 실무 예시 매핑

| 문제 | 학습 패러다임 | 모델 복잡도 | 구체적 접근 |
|------|--------------|------------|-----------|
| 고객 이탈 예측 (라벨 충분) | 지도 학습 | Traditional ML | Logistic Regression, XGBoost |
| 대규모 이미지 분류 | 지도 학습 | Deep Learning (CNN) | ResNet + ImageNet 사전학습 |
| 고객 세분화 (라벨 없음) | 비지도 학습 | Traditional ML | K-Means |
| 텍스트 생성 | 자기지도 학습 | Deep Learning (Transformer) | GPT 사전학습 + 파인튜닝 |
| 의료 영상 (라벨 10%) | 반지도 학습 | Deep Learning (CNN) | Pseudo-labeling |
| 게임 AI | 강화 학습 | Deep RL | PPO, DQN |
| 제조 이상 탐지 | 비지도 학습 | Deep Learning | Autoencoder |

---

## 다음 학습 경로

### 학습 로드맵 시작
- [[AI 기초 개요]]: 9단계 학습 로드맵과 상세 가이드 (여기서 시작!)

### 학습 패러다임 깊이 이해
- [[MLDL Basic/1. 학습 패러다임]]: 각 패러다임의 상세 설명과 실습

### 딥러닝 아키텍처 학습
- [[MLDL Basic/5. 신경망 기본 구조]]: MLP, 역전파 이해
- [[MLDL Basic/8. 합성곱 신경망 기초]]: CNN 아키텍처
- [[MLDL Basic/9. 시퀀스 모델 기초]]: RNN, Transformer

---

## 참고 자료

**서적**
- "Artificial Intelligence: A Modern Approach" (Russell & Norvig) - AI 전체 개관
- "Pattern Recognition and Machine Learning" (Bishop) - Traditional ML
- "Deep Learning" (Goodfellow et al.) - 딥러닝 기초

**온라인 강의**
- Andrew Ng - Machine Learning (Coursera)
- Stanford CS231n - CNN for Visual Recognition
- Stanford CS224n - NLP with Deep Learning

**논문**
- "Attention is All You Need" (Transformer)
- "BERT: Pre-training of Deep Bidirectional Transformers"
- "Playing Atari with Deep Reinforcement Learning" (DQN)
