## TL;DR
- 합성곱 신경망(CNN)은 이미지와 같은 격자 형태 데이터를 처리하기 위해 설계된 신경망이다.
- 합성곱 연산은 지역적 패턴을 감지하고, 파라미터 공유를 통해 효율적으로 특징을 추출한다.
- Pooling, Stride, Padding 등의 개념을 이해하면 CNN 구조를 유연하게 설계할 수 있다.

## 핵심 개념

### 합성곱 연산 (Convolution)

합성곱은 입력 이미지에 필터(커널)를 슬라이딩하며 적용하는 연산이다.

**2D 합성곱 수식**:

$$
(I * K)(i, j) = \sum_{m} \sum_{n} I(i+m, j+n) \cdot K(m, n)
$$

- $I$: 입력 이미지 (Input)
- $K$: 커널/필터 (Kernel/Filter)
- $(i, j)$: 출력 특징 맵의 위치
- $(m, n)$: 커널 내 위치

**PyTorch 표기**:

$$
Y = X * W + b
$$

- $X \in \mathbb{R}^{C_{\text{in}} \times H \times W}$: 입력 (채널, 높이, 너비)
- $W \in \mathbb{R}^{C_{\text{out}} \times C_{\text{in}} \times K_H \times K_W}$: 가중치
- $Y \in \mathbb{R}^{C_{\text{out}} \times H' \times W'}$: 출력

---

### 출력 크기 계산

합성곱 후 출력 크기:

$$
H_{\text{out}} = \left\lfloor \frac{H_{\text{in}} + 2P - K}{S} \right\rfloor + 1
$$

$$
W_{\text{out}} = \left\lfloor \frac{W_{\text{in}} + 2P - K}{S} \right\rfloor + 1
$$

- $H_{\text{in}}, W_{\text{in}}$: 입력 높이, 너비
- $P$: 패딩 (Padding)
- $K$: 커널 크기
- $S$: 스트라이드 (Stride)

---

### 주요 개념

**1. 스트라이드 (Stride)**

필터를 이동하는 간격

- $S=1$: 한 칸씩 이동 (기본)
- $S=2$: 두 칸씩 이동 (다운샘플링 효과)

**2. 패딩 (Padding)**

입력 주변에 값(보통 0)을 추가

- `valid`: 패딩 없음
- `same`: 출력 크기 = 입력 크기 ($P = (K-1)/2$)

**3. 채널 (Channel)**

- 입력 채널: RGB 이미지는 3채널
- 출력 채널: 필터 개수 = 특징 맵 개수

---

## CNN 기본 블록

### Conv-ReLU-Pool

가장 기본적인 CNN 블록:

```python
import torch.nn as nn

block = nn.Sequential(
    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(kernel_size=2, stride=2)
)
```

**동작**:
1. Conv: 특징 추출
2. ReLU: 비선형 활성화
3. Pool: 공간 축소, 계산량 감소

---

### 풀링 (Pooling)

공간 차원을 축소하여 파라미터 수를 줄이고 불변성을 증가시킨다.

**Max Pooling**:

$$
y_{i,j} = \max_{m,n \in \text{window}} x_{i+m, j+n}
$$

영역 내 최댓값 선택

**Average Pooling**:

$$
y_{i,j} = \frac{1}{K^2} \sum_{m,n \in \text{window}} x_{i+m, j+n}
$$

영역 내 평균값 계산

```python
# Max Pooling
max_pool = nn.MaxPool2d(kernel_size=2, stride=2)
# (batch, 64, 32, 32) → (batch, 64, 16, 16)

# Average Pooling
avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)
```

---

## 파라미터 수 계산

**Conv2d 파라미터**:

$$
\text{Params} = C_{\text{out}} \times (C_{\text{in}} \times K_H \times K_W + 1)
$$

+1은 편향(bias)

**예시**: `Conv2d(3, 64, kernel_size=3)`

$$
\text{Params} = 64 \times (3 \times 3 \times 3 + 1) = 64 \times 28 = 1{,}792
$$

---

## 전형적인 CNN 구조

### LeNet-5 스타일

```python
class LeNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        # (batch, 1, 32, 32)
        x = self.pool(F.relu(self.conv1(x)))  # (batch, 6, 14, 14)
        x = self.pool(F.relu(self.conv2(x)))  # (batch, 16, 5, 5)
        x = x.view(x.size(0), -1)  # Flatten
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```

---

### 현대적 CNN 블록 (Conv-BN-ReLU)

```python
def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):
    """현대적 CNN 블록"""
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),
        nn.BatchNorm2d(out_channels),
        nn.ReLU(inplace=True)
    )

class ModernCNN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.features = nn.Sequential(
            conv_block(3, 64),
            conv_block(64, 64),
            nn.MaxPool2d(2, 2),

            conv_block(64, 128),
            conv_block(128, 128),
            nn.MaxPool2d(2, 2),

            conv_block(128, 256),
            conv_block(256, 256),
            nn.MaxPool2d(2, 2),
        )

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),  # Global Average Pooling
            nn.Flatten(),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
```

---

## 고급 기법

### 1x1 Convolution

채널 수를 조절하거나 비선형성을 추가

```python
nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1)
```

**용도**:
- 차원 축소/확장
- 계산량 감소 (Bottleneck 구조)

---

### Depthwise Separable Convolution

파라미터 효율적인 합성곱

**Depthwise Convolution**: 각 채널을 독립적으로 처리

$$
\text{Params}_{\text{depthwise}} = C_{\text{in}} \times K \times K
$$

**Pointwise Convolution**: 1x1 합성곱으로 채널 결합

$$
\text{Params}_{\text{pointwise}} = C_{\text{in}} \times C_{\text{out}}
$$

**총 파라미터**:

$$
\text{Params}_{\text{separable}} = C_{\text{in}} \times K^2 + C_{\text{in}} \times C_{\text{out}}
$$

일반 합성곱 대비 $\frac{1}{C_{\text{out}}} + \frac{1}{K^2}$배로 감소

```python
# Depthwise Separable Convolution
nn.Sequential(
    nn.Conv2d(64, 64, kernel_size=3, padding=1, groups=64),  # Depthwise
    nn.Conv2d(64, 128, kernel_size=1)  # Pointwise
)
```

---

### Global Average Pooling

Fully Connected 층을 대체

```python
nn.AdaptiveAvgPool2d((1, 1))  # 출력: (batch, channels, 1, 1)
```

**장점**:
- 파라미터 수 대폭 감소
- 과적합 방지
- 입력 크기에 무관

---

## 유명 CNN 아키텍처

### AlexNet (2012)
- 8층 (5 Conv + 3 FC)
- ReLU, Dropout, Data Augmentation
- ImageNet 우승

### VGGNet (2014)
- 3x3 작은 필터를 깊게 쌓음
- VGG16, VGG19

### ResNet (2015)
- Residual Connection (Skip Connection)
- 152층까지 학습 가능
- He et al.

$$
\mathbf{y} = F(\mathbf{x}) + \mathbf{x}
$$

```python
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)

    def forward(self, x):
        residual = x
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += residual  # Skip connection
        out = F.relu(out)
        return out
```

---

## 실습 예제

### 간단한 CIFAR-10 분류기

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class CIFAR10CNN(nn.Module):
    def __init__(self):
        super().__init__()
        # CIFAR-10: 32x32x3 입력
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)

        self.pool = nn.MaxPool2d(2, 2)

        self.fc1 = nn.Linear(128 * 4 * 4, 256)
        self.fc2 = nn.Linear(256, 10)

        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        # Input: (batch, 3, 32, 32)
        x = self.pool(F.relu(self.conv1(x)))  # (batch, 32, 16, 16)
        x = self.pool(F.relu(self.conv2(x)))  # (batch, 64, 8, 8)
        x = self.pool(F.relu(self.conv3(x)))  # (batch, 128, 4, 4)

        x = x.view(x.size(0), -1)  # Flatten: (batch, 128*4*4)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

# 모델 생성 및 테스트
model = CIFAR10CNN()
x = torch.randn(4, 3, 32, 32)
output = model(x)
print(output.shape)  # (4, 10)
```

---

### 특징 맵 시각화

```python
import matplotlib.pyplot as plt

def visualize_feature_maps(model, image):
    """첫 번째 Conv 층의 특징 맵 시각화"""
    model.eval()

    # 첫 번째 Conv 층 출력 추출
    with torch.no_grad():
        features = model.conv1(image.unsqueeze(0))  # (1, 32, 32, 32)

    # 32개 필터의 출력 시각화
    fig, axes = plt.subplots(4, 8, figsize=(16, 8))
    for i, ax in enumerate(axes.flat):
        if i < features.shape[1]:
            ax.imshow(features[0, i].cpu(), cmap='viridis')
            ax.axis('off')
    plt.tight_layout()
    plt.show()
```

---

## 설계 가이드

### 일반 원칙

1. **작은 필터 사용**: 3x3이 표준
2. **깊게 쌓기**: 여러 층으로 계층적 특징 학습
3. **Batch Normalization**: 각 Conv 뒤에 추가
4. **Pooling 위치**: 2-3개 Conv 후 한 번

### 파라미터 효율화

**문제**: FC 층이 파라미터의 대부분을 차지

**해결**:
- Global Average Pooling 사용
- 1x1 Conv로 채널 수 감소
- Depthwise Separable Conv

---

## 연습 문제

### 기초
1. 입력 크기 32x32, 커널 크기 5x5, 스트라이드 1, 패딩 2일 때 출력 크기를 계산하시오.
2. Conv2d(3, 64, kernel_size=3)의 파라미터 수를 계산하시오.
3. Max Pooling과 Average Pooling의 차이를 설명하시오.

### 중급
4. MNIST 데이터셋에 대해 3-층 CNN을 구현하고 98% 이상의 정확도를 달성하시오.
5. 첫 번째 Conv 층의 필터(커널)를 시각화하고 무엇을 학습했는지 분석하시오.
6. ResNet의 Residual Block을 구현하고 일반 CNN과 학습 속도를 비교하시오.

### 고급
7. Depthwise Separable Convolution을 사용하여 MobileNet 스타일 모델을 구현하시오.
8. CIFAR-10에서 Data Augmentation(회전, 크롭, 색상 변환)을 적용하고 성능 향상을 측정하시오.
9. Grad-CAM을 구현하여 CNN이 이미지의 어느 부분을 보고 판단하는지 시각화하시오.

---

## 참고 자료

**논문**
- LeCun et al., "Gradient-Based Learning Applied to Document Recognition" (1998) - LeNet
- Krizhevsky et al., "ImageNet Classification with Deep CNNs" (2012) - AlexNet
- Simonyan & Zisserman, "Very Deep Convolutional Networks" (2014) - VGG
- He et al., "Deep Residual Learning for Image Recognition" (2015) - ResNet
- Howard et al., "MobileNets: Efficient Convolutional Neural Networks" (2017)

**온라인 강의**
- Stanford CS231n: Lecture 5 - Convolutional Neural Networks
- FastAI: Practical Deep Learning for Coders

---

## 다음 학습
- [[Foundations/9. 시퀀스 모델 기초]]
- [[Foundations/5. 신경망 기본 구조]]
- [[Operators/3. 합성곱 연산자]]
