## TL;DR
- 손실 함수(loss)는 학습 중 최적화하려는 목표를 수치화하고, 평가 지표(metric)는 모델이 실제로 얼마나 잘 동작하는지 측정한다.
- 분류, 회귀, 랭킹 등 각 문제 유형에 맞는 손실·지표 조합을 이해하고, 클래스 불균형이나 확률 보정(calibration) 이슈를 해결할 전략을 마련해야 한다.
- 손실과 지표가 불일치하면 학습 방향이 어긋날 수 있으므로, 지표를 surrogate loss로 근사하거나 커스텀 손실을 설계하기도 한다.

```
Surrogate Loss(대리 손실) =  
진짜 손실 함수는 미분 불가능하거나 직접 최적화하기 어렵기 때문에,  
그걸 근사(approximate) 해서 대신 사용하는 미분 가능한(loss surrogate) 손실 함수.
```

## 손실 함수 분류

### 경험적 위험 최소화 (Empirical Risk Minimization, ERM)

전체 데이터에 대한 평균 손실을 최소화한다:

$$
L(\theta) = \frac{1}{N} \sum_{i=1}^{N} \ell(f_\theta(x_i), y_i)
$$

- $\theta$: 모델 파라미터
- $N$: 데이터 개수
- $\ell$: 개별 샘플에 대한 손실 함수
- $f_\theta$: 파라미터 $\theta$를 가진 모델

학습률, 정규화, 옵티마이저는 이 손실을 기준으로 동작한다.

---

### 분류 손실 (Classification Loss)

**Cross Entropy Loss**

확률 분포 간 차이를 측정, softmax와 함께 사용:

$$
\ell_{\text{CE}} = -\sum_{c=1}^{C} y_c \log p_c
$$

- $C$: 클래스 개수
- $y_c$: 정답 레이블 (one-hot 인코딩)
- $p_c$: 모델이 예측한 클래스 $c$의 확률

**Binary Cross Entropy (BCE)**

이진 분류를 위한 손실 함수:

$$
\ell_{\text{BCE}} = -[y \log p + (1-y) \log(1-p)]
$$

- $y \in \{0, 1\}$: 정답 레이블
- $p$: 모델이 예측한 확률

**Focal Loss**

희귀 클래스에서 손실 가중치를 높여 클래스 불균형 완화:

$$
\ell_{\text{FL}} = -\alpha (1-p)^\gamma \log p
$$

- $\alpha$: 클래스 가중치
- $\gamma$: focusing parameter (보통 2)
- $p$: 정답 클래스 확률

**Hinge Loss**

최대 마진 분류(SVM)의 surrogate loss:

$$
\ell_{\text{hinge}} = \max(0, 1 - y \cdot f(x))
$$

- $y \in \{-1, +1\}$: 정답 레이블
- $f(x)$: 모델의 출력 (로짓)

---

### 회귀 손실 (Regression Loss)

**L2 Loss (Mean Squared Error, MSE)**

큰 오차에 민감, 미분 가능:

$$
\ell_{\text{MSE}} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
$$

- $y_i$: 정답 값
- $\hat{y}_i$: 예측 값

**L1 Loss (Mean Absolute Error, MAE)**

Outlier에 강인, 미분 불연속:

$$
\ell_{\text{MAE}} = \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|
$$

**Huber Loss**

L1과 L2 사이의 타협, $\delta$ 파라미터로 전환 지점 제어:

$$
\ell_{\text{Huber}} = \begin{cases}
\frac{1}{2}(y - \hat{y})^2 & \text{if } |y - \hat{y}| \le \delta \\
\delta |y - \hat{y}| - \frac{1}{2}\delta^2 & \text{otherwise}
\end{cases}
$$

- $\delta$: 임계값 파라미터

**Quantile Loss**

특정 분위수 예측:

$$
\ell_{\tau}(y, \hat{y}) = \max[\tau(y - \hat{y}), (\tau - 1)(y - \hat{y})]
$$

- $\tau \in (0, 1)$: 목표 분위수 (예: 0.9는 90% 분위수)

---

### 랭킹/추천 손실

**Pairwise Hinge Loss**: 선호 순서를 학습

**BPR (Bayesian Personalized Ranking)**: 사용자-아이템 순위 학습

**Listwise Loss**: 전체 순열에 대한 확률 최적화 (LambdaRank, ListNet)

---

### 기타 손실

**GAN Loss**

$$
\min_G \max_D \mathbb{E}_{x \sim p_{\text{data}}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]
$$

- $G$: 생성자 (Generator)
- $D$: 판별자 (Discriminator)
- $z$: 잠재 벡터

**Contrastive Loss / InfoNCE**: Representation learning

**KL Divergence**: 확률 분포 간 거리

$$
D_{\text{KL}}(P \| Q) = \sum_{x} P(x) \log \frac{P(x)}{Q(x)}
$$

## 평가 지표 개요
- 분류 지표: Accuracy, Precision, Recall, F1, ROC-AUC, PR-AUC.
- 회귀 지표: RMSE, MAE, R², MAPE.
- 불균형 데이터: Balanced Accuracy, MCC, F-beta.
- 랭킹: MAP, NDCG, Hit@K.
- Calibration: Brier Score, Expected Calibration Error(ECE).

## 손실과 지표의 불일치 문제
- Accuracy를 높이고 싶지만 Cross Entropy가 surrogate loss로 사용된다 → 일반적으로 잘 대응하지만 클래스 불균형 시 precision/recall을 직접 고려해야 함.
- F1-score는 미분 불가능 → differentiable surrogate(Focal loss, differentiable F-measure) 사용.
- ROC-AUC를 직접 최적화하기 어렵기 때문에, pairwise loss로 대체하거나 differentiable approximation을 사용.

## PyTorch에서 손실/지표 사용 예
```python
import torch
import torch.nn.functional as F

logits = torch.randn(8, 5)
targets = torch.randint(0, 5, (8,))

loss = F.cross_entropy(logits, targets)

pred = logits.argmax(dim=1)
accuracy = (pred == targets).float().mean()
print("loss=", loss.item(), "accuracy=", accuracy.item())
```
- 손실은 gradient를 통해 학습에 사용되며, 지표는 gradient가 끊기더라도 SKlearn 또는 PyTorch Lightning metric 등으로 계산해 기록한다.