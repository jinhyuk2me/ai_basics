# AI Basics

AI/딥러닝을 공부하면서 정리한 학습 노트입니다.

## 소개

이 저장소는 Obsidian Vault로 관리하는 AI/딥러닝 기초 학습 노트입니다. 수학, 프로그래밍, 머신러닝 기초 개념을 단계별로 정리했습니다.

### 특징

- 정의 → 예제 → 실습 → 연습문제 순서로 구성
- 수학 이론과 Python/PyTorch 실습 코드를 함께 제공
- Obsidian 링크로 관련 개념들을 연결
- 한국어로 작성 (영문 용어 병기)

## 저장소 구조

```
ai_basics/
├── Math/                      # 수학 기초
│   ├── Linear Algebra/        # 선형대수
│   ├── Calculus/              # 미적분
│   ├── Probability/           # 확률과 통계
│   ├── Optimization/          # 최적화 이론
│   ├── Discrete/              # 그래프 이론
│   └── Reference/             # 용어집 및 참고자료
├── Programming/               # 프로그래밍 기초
│   ├── 파이썬 기초.md
│   └── 자료구조와 알고리즘.md
├── ML Foundations/            # 머신러닝 기초 개념
│   ├── 학습 패러다임.md
│   ├── 손실 함수와 평가 지표.md
│   ├── 머신러닝 최적화.md
│   └── 정규화와 일반화.md
├── Operators/                 # 핵심 연산자
│   ├── 선형 연산자.md
│   ├── 행렬 분해.md
│   └── 합성곱 연산자.md
├── AI 기초 개요.md            # 전체 학습 로드맵
└── CLAUDE.md                  # 노트 작성 가이드라인
```

## 학습 로드맵

### 1단계: 수학 기초
**핵심 질문**: 선형대수·미적분·확률이 왜 필요한가?
- 시작: `Math/Linear Algebra/선형대수 핵심 개요.md`
- 필수 개념: 벡터, 행렬, 고유값, 미분, 그래디언트
- 활용: 신경망의 연산, 역전파, 파라미터 업데이트

### 2단계: 확률/통계·최적화
**핵심 질문**: 불확실성과 손실 최소화를 어떻게 다루나?
- 시작: `Math/Probability/확률과 통계 입문.md`
- 필수 개념: 확률분포, 기댓값, 경사하강법, 볼록 최적화
- 활용: 확률적 모델링, 손실 함수 최소화

### 3단계: 프로그래밍 기초
**핵심 질문**: Python과 자료구조를 어떻게 활용하나?
- 시작: `Programming/파이썬 기초.md`
- 필수 개념: NumPy, 자료구조, 알고리즘 복잡도
- 활용: 데이터 처리, 효율적 구현

### 4단계: ML 개념
**핵심 질문**: 지도/비지도 학습과 평가 지표는 무엇인가?
- 시작: `ML Foundations/학습 패러다임.md`
- 필수 개념: 훈련/검증/테스트, 손실 함수, 정확도/F1 스코어
- 활용: 모델 학습 및 평가

### 5단계: 최적화/정규화
**핵심 질문**: 학습 절차를 어떻게 안정화하나?
- 시작: `ML Foundations/머신러닝 최적화.md`
- 필수 개념: SGD, Adam, 배치 정규화, 드롭아웃
- 활용: 안정적이고 일반화된 모델 학습

### 6단계: 연산자/그래프
**핵심 질문**: 핵심 연산자와 계산 그래프는 어떻게 동작하나?
- 시작: `Operators/선형 연산자.md`
- 필수 개념: 선형 변환, 합성곱, 계산 그래프
- 활용: PyTorch 연산 이해, 자동 미분

## 노트 구조

각 노트는 다음 구조로 작성됩니다:

1. **TL;DR**: 핵심 요약
2. **핵심 개념**: 정의, 정리, 설명
3. **수학적 전개**: 정리 증명 및 유도 (필요시)
4. **예제**: 구체적인 예제
5. **실습 예제**: Python/NumPy/PyTorch 코드
6. **연습 문제**: 난이도별 문제
7. **참고 자료**: 교과서, 논문, 강의 링크
8. **다음 학습 경로**: 관련 노트 링크

## 시작하기

### Obsidian으로 보기
1. [Obsidian](https://obsidian.md/) 설치
2. 저장소 클론
   ```bash
   git clone https://github.com/yourusername/ai_basics.git
   ```
3. Obsidian에서 "Open folder as vault" → `ai_basics` 폴더 선택
4. `AI 기초 개요.md`에서 시작

### GitHub에서 보기
- `AI 기초 개요.md`에서 학습 로드맵 확인 후 필요한 노트로 이동

### 로컬에서 보기
- VS Code, Typora 등 Markdown 에디터 사용

## 학습 전략

### Layered Approach
- 모르는 개념이 나오면 해당 단계 노트로 돌아가서 요약 확인
- 필요 시 참고 자료 섹션의 외부 링크 활용

### 실습 병행
- 수학 노트에서도 간단한 NumPy/PyTorch 코드로 개념 구현
- ML 노트에서는 실제 데이터셋으로 미니 프로젝트 수행

### 용어 정리
- `Math/Reference/개념 용어집.md`에서 용어 빠르게 조회
- 각 노트 말미의 참고 자료에서 심화 학습

## 기여

오류 수정이나 개선 제안은 이슈나 PR로 남겨주세요.

### 작성 원칙
- 한국어 작성 (영문 용어 병기)
- 수식 뒤 기호 설명
- 실행 가능한 코드 제공
- 관련 노트와 링크 연결

## 주요 노트 미리보기

### Math
- [선형대수 핵심 개요](Math/Linear%20Algebra/선형대수%20핵심%20개요.md)
- [미분과 미분법](Math/Calculus/미분과%20미분법.md)
- [경사하강법과 변형](Math/Optimization/경사하강법과%20변형.md)
- [확률과 통계 입문](Math/Probability/확률과%20통계%20입문.md)

### ML Foundations
- [학습 패러다임](ML%20Foundations/학습%20패러다임.md)
- [손실 함수와 평가 지표](ML%20Foundations/손실%20함수와%20평가%20지표.md)
- [머신러닝 최적화](ML%20Foundations/머신러닝%20최적화.md)

### Operators
- [선형 연산자](Operators/선형%20연산자.md)
- [합성곱 연산자](Operators/합성곱%20연산자.md)

## 참고 자료

### 교과서
- **선형대수**: *Linear Algebra and Its Applications* (Gilbert Strang)
- **미적분**: *Calculus* (James Stewart)
- **확률**: *Introduction to Probability* (Bertsekas & Tsitsiklis)
- **딥러닝**: *Deep Learning* (Goodfellow, Bengio, Courville)

### 온라인 강의
- [MIT 18.06 Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/)
- [3Blue1Brown - Essence of Linear Algebra](https://www.3blue1brown.com/topics/linear-algebra)
- [Stanford CS229 - Machine Learning](https://see.stanford.edu/Course/CS229)

## 라이선스

이 프로젝트는 교육 목적으로 자유롭게 사용 가능합니다.

## 문의

- 이슈 등록: [GitHub Issues](https://github.com/yourusername/ai_basics/issues)
- 개선 제안: Pull Request 환영

---

*Last updated: 2025-11-03*
